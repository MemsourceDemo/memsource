<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE chapter PUBLIC "-//ES//DTD book DTD version 5.5.0//EN//XML" "https://www.elsevier.com/__data/assets/text_file/0008/275669/bk55_book550_dtd.txt" [<!ENTITY f005-001-9780323552295 SYSTEM "f005-001-9780323552295" NDATA IMAGE><!ENTITY f005-002-9780323552295 SYSTEM "f005-002-9780323552295" NDATA IMAGE><!ENTITY f005-003-9780323552295 SYSTEM "f005-003-9780323552295" NDATA IMAGE><!ENTITY f005-004-9780323552295 SYSTEM "f005-004-9780323552295" NDATA IMAGE><!ENTITY f005-005-9780323552295 SYSTEM "f005-005-9780323552295" NDATA IMAGE><!ENTITY f005-006-9780323552295 SYSTEM "f005-006-9780323552295" NDATA IMAGE><!ENTITY f005-007-9780323552295 SYSTEM "f005-007-9780323552295" NDATA IMAGE><!ENTITY f005-008-9780323552295 SYSTEM "f005-008-9780323552295" NDATA IMAGE><!ENTITY f005-009-9780323552295 SYSTEM "f005-009-9780323552295" NDATA IMAGE><!ENTITY f005-010-9780323552295 SYSTEM "f005-010-9780323552295" NDATA IMAGE><!ENTITY f005-011-9780323552295 SYSTEM "f005-011-9780323552295" NDATA IMAGE><!ENTITY f005-012-9780323552295 SYSTEM "f005-012-9780323552295" NDATA IMAGE><!ENTITY f005-013-9780323552295 SYSTEM "f005-013-9780323552295" NDATA IMAGE><!ENTITY f005-014-9780323552295 SYSTEM "f005-014-9780323552295" NDATA IMAGE><!ENTITY f005-015-9780323552295 SYSTEM "f005-015-9780323552295" NDATA IMAGE><!ENTITY f005-016-9780323552295 SYSTEM "f005-016-9780323552295" NDATA IMAGE><!ENTITY f005-017a-9780323552295 SYSTEM "f005-017a-9780323552295" NDATA IMAGE><!ENTITY f005-017b-9780323552295 SYSTEM "f005-017b-9780323552295" NDATA IMAGE><!ENTITY f005-017c-9780323552295 SYSTEM "f005-017c-9780323552295" NDATA IMAGE><!ENTITY f005-018-9780323552295 SYSTEM "f005-018-9780323552295" NDATA IMAGE><!ENTITY f005-019-9780323552295 SYSTEM "f005-019-9780323552295" NDATA IMAGE><!ENTITY f005-020-9780323552295 SYSTEM "f005-020-9780323552295" NDATA IMAGE><!ENTITY if005-001-9780323552295 SYSTEM "if005-001-9780323552295" NDATA IMAGE><!ENTITY if005-002-9780323552295 SYSTEM "if005-002-9780323552295" NDATA IMAGE><!ENTITY if005-003-9780323552295 SYSTEM "if005-003-9780323552295" NDATA IMAGE><!ENTITY if005-004-9780323552295 SYSTEM "if005-004-9780323552295" NDATA IMAGE><!ENTITY if005-005-9780323552295 SYSTEM "if005-005-9780323552295" NDATA IMAGE><!ENTITY if005-006-9780323552295 SYSTEM "if005-006-9780323552295" NDATA IMAGE><!ENTITY if005-007-9780323552295 SYSTEM "if005-007-9780323552295" NDATA IMAGE><!ENTITY if005-008-9780323552295 SYSTEM "if005-008-9780323552295" NDATA IMAGE><!ENTITY if005-009-9780323552295 SYSTEM "if005-009-9780323552295" NDATA IMAGE><!ENTITY if005-010-9780323552295 SYSTEM "if005-010-9780323552295" NDATA IMAGE><!ENTITY if005-011-9780323552295 SYSTEM "if005-011-9780323552295" NDATA IMAGE><!ENTITY if005-012-9780323552295 SYSTEM "if005-012-9780323552295" NDATA IMAGE><!ENTITY if005-013-9780323552295 SYSTEM "if005-013-9780323552295" NDATA IMAGE><!ENTITY if005-014-9780323552295 SYSTEM "if005-014-9780323552295" NDATA IMAGE><!ENTITY if005-015-9780323552295 SYSTEM "if005-015-9780323552295" NDATA IMAGE><!ENTITY if005-016-9780323552295 SYSTEM "if005-016-9780323552295" NDATA IMAGE><!ENTITY t005-001-9780323552295 SYSTEM "t005-001-9780323552295" NDATA IMAGE><!ENTITY t005-002-9780323552295 SYSTEM "t005-002-9780323552295" NDATA IMAGE><!ENTITY t005-003-9780323552295 SYSTEM "t005-003-9780323552295" NDATA IMAGE><!ENTITY t005-004-9780323552295 SYSTEM "t005-004-9780323552295" NDATA IMAGE><!ENTITY t005-005-9780323552295 SYSTEM "t005-005-9780323552295" NDATA IMAGE><!ENTITY t005-006-9780323552295 SYSTEM "t005-006-9780323552295" NDATA IMAGE><!ENTITY t005-007-9780323552295 SYSTEM "t005-007-9780323552295" NDATA IMAGE><!ENTITY t005-010-9780323552295 SYSTEM "t005-010-9780323552295" NDATA IMAGE>]><chapter docsubtype="chp" id="c00005" version="5.5" xml:lang="en" xmlns="http://www.elsevier.com/xml/bk/dtd" xmlns:sb="http://www.elsevier.com/xml/common/dtd" xmlns:mml="http://www.elsevier.com/xml/common/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:xlink="http://www.w3.org/1999/xlink"><info><ce:pii>B978-0-323-55229-5.00005-X</ce:pii><ce:doi>10.1016/B978-0-323-55229-5.00005-X</ce:doi><ce:isbn>978-0-323-55229-5</ce:isbn><ce:copyright type="full-transfer" year="2019">Elsevier Inc.</ce:copyright></info><ce:floats><ce:figure id="f0010"><ce:label>Fig. 5.1</ce:label><ce:caption id="ca0010"><ce:simple-para id="sp0015" role="caption">Distribution of newly reported confirmed cases of hepatitis C virus infection in Massachusetts for 2009.</ce:simple-para></ce:caption><ce:alt-text id="atte0010" role="short">Fig. 5.1</ce:alt-text><ce:source>(Modified from Centers for Disease Control and Prevention. Hepatitis C virus infection among adolescents and young adults: Massachusetts, 2002–2009. <ce:italic>MMWR Morb Mortal Wkly Rep</ce:italic>. 2011;60:537–541.)</ce:source><ce:link id="ln0010" locator="f005-001-9780323552295" xlink:href="pii:B978032355229500005X/f005-001-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0015"><ce:label>Fig. 5.2</ce:label><ce:caption id="ca0015"><ce:simple-para id="sp0020" role="caption">Distribution of achieved calculated low-density lipoprotein cholesterol <ce:italic>(LDL-C)</ce:italic> level at 1 month among patients who did not have a primary efficacy or prespecified safety event prior to the sample.</ce:simple-para></ce:caption><ce:alt-text id="atte0015" role="short">Fig. 5.2</ce:alt-text><ce:source>(Data from Giugliano RP, Wiviott SD, Blazing MA, et al. Long-term safety and efficacy of achieving very low levels of low-density lipoprotein cholesterol: a prespecified analysis of the IMPROVE-IT trial. <ce:italic>JAMA Cardiol</ce:italic>. 2017;2:547–555.)</ce:source><ce:link id="ln0015" locator="f005-002-9780323552295" xlink:href="pii:B978032355229500005X/f005-002-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0020"><ce:label>Fig. 5.3</ce:label><ce:caption id="ca0030"><ce:simple-para id="sp0035" role="caption">(A to G) The effects of choosing different cutoff levels to define a positive test result when screening for diabetes using a continuous marker, blood sugar, in a hypothetical population. (See discussion in the text under the subheading “<ce:cross-ref id="crf0045" refid="s0025">Tests of Continuous Variables</ce:cross-ref>” on page 97.)</ce:simple-para></ce:caption><ce:alt-text id="atte0020" role="short">Fig. 5.3</ce:alt-text><ce:link id="ln0030" locator="f005-003-9780323552295" xlink:href="pii:B978032355229500005X/f005-003-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0025"><ce:label>Fig. 5.4</ce:label><ce:caption id="ca0035"><ce:simple-para id="sp0040" role="caption">(A) Distribution of blood sugar levels in hospital patients with diabetes and without diabetes. (The number of people with diabetes is shown for each specific blood sugar level in the <ce:italic>[upper]</ce:italic> distribution for persons <ce:italic>without</ce:italic> diabetes. Because of limited space, the number of people for each specific level of blood sugar is not shown in the <ce:italic>[lower]</ce:italic> distribution for persons <ce:italic>with</ce:italic> diabetes.) (B) and (C) show two different blood sugar cutpoints that were used in the study to define diabetes. Data from the graphs are presented to the right of each graph in a 2 × 2 table. (B) When a blood sugar cutpoint of ≥80 mg/dL is used to define diabetes in this population, sensitivity of the screening test is 100%, but specificity is low. (C) When a blood sugar cutpoint of ≥200 mg/dL is used to define diabetes in this population, sensitivity of the screening test is low, but specificity is 100%. (See explanation in the text under the subheading “<ce:cross-ref id="crf0090" refid="s0025">Tests of Continuous Variables</ce:cross-ref>” on <ce:cross-ref id="crf9000" refid="s0025">page 97</ce:cross-ref>.) <ce:italic>FN</ce:italic>, False negatives; <ce:italic>FP</ce:italic>, false positives; <ce:italic>TN</ce:italic>, true negatives; <ce:italic>TP</ce:italic>, true positives.</ce:simple-para></ce:caption><ce:alt-text id="atte0025" role="short">Fig. 5.4</ce:alt-text><ce:source>(Modified from Blumberg M. Evaluating health screening procedures. <ce:italic>Oper Res</ce:italic>. 1957;5:351–360.)</ce:source><ce:link id="ln0035" locator="f005-004-9780323552295" xlink:href="pii:B978032355229500005X/f005-004-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0030"><ce:label>Fig. 5.5</ce:label><ce:caption id="ca0040"><ce:simple-para id="sp0045" role="caption">Diagram showing four possible groups resulting from screening with a dichotomous test.</ce:simple-para></ce:caption><ce:alt-text id="atte0030" role="short">Fig. 5.5</ce:alt-text><ce:link id="ln0040" locator="f005-005-9780323552295" xlink:href="pii:B978032355229500005X/f005-005-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0035"><ce:label>Fig. 5.6</ce:label><ce:caption id="ca0045"><ce:simple-para id="sp0050" role="caption">Diagram showing the two groups of people resulting from screening with a dichotomous screening test: all people with positive test results and all people with negative test results.</ce:simple-para></ce:caption><ce:alt-text id="atte0035" role="short">Fig. 5.6</ce:alt-text><ce:link id="ln0045" locator="f005-006-9780323552295" xlink:href="pii:B978032355229500005X/f005-006-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0040"><ce:label>Fig. 5.7</ce:label><ce:caption id="ca0050"><ce:simple-para id="sp0055" role="caption">Hypothetical example of a two-stage screening program. (A) Findings using Test 1 in a population of 10,000 people. (B) Findings using Test 2 in participants who tested positive using Test 1. (See explanation in the text under the subheading “<ce:cross-ref id="crf0120" refid="s0035">Sequential (Two-Stage) Testing</ce:cross-ref>” on <ce:cross-ref id="crf9005" refid="p0115">page 99</ce:cross-ref>.)</ce:simple-para></ce:caption><ce:alt-text id="atte0040" role="short">Fig. 5.7</ce:alt-text><ce:link id="ln0050" locator="f005-007-9780323552295" xlink:href="pii:B978032355229500005X/f005-007-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0045"><ce:label>Fig. 5.8</ce:label><ce:caption id="ca0060"><ce:simple-para id="sp0065" role="caption">(A to F) Net sensitivity: hypothetical example of simultaneous testing. (See explanation in the text under the subheading “<ce:cross-ref id="crf0140" refid="s0045">Net Sensitivity Using Two Simultaneous Tests</ce:cross-ref>” on <ce:cross-ref id="crf9010" refid="s0045">page 102</ce:cross-ref>.)</ce:simple-para></ce:caption><ce:alt-text id="atte0045" role="short">Fig. 5.8</ce:alt-text><ce:link id="ln0060" locator="f005-008-9780323552295" xlink:href="pii:B978032355229500005X/f005-008-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0050"><ce:label>Fig. 5.9</ce:label><ce:caption id="ca0075"><ce:simple-para id="sp0080" role="caption">(A to F) Net specificity: hypothetical example of simultaneous testing. (See explanation in the text under the subheading “<ce:cross-ref id="crf0185" refid="s0050">Net Specificity Using Two Simultaneous Tests</ce:cross-ref>” on <ce:cross-ref id="crf9015" refid="s0050">page 104</ce:cross-ref>.)</ce:simple-para></ce:caption><ce:alt-text id="atte0050" role="short">Fig. 5.9</ce:alt-text><ce:link id="ln0080" locator="f005-009-9780323552295" xlink:href="pii:B978032355229500005X/f005-009-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0055"><ce:label>Fig. 5.10</ce:label><ce:caption id="ca0085"><ce:simple-para id="sp0090" role="caption">“Whoa—<ce:italic>way</ce:italic> too much information.” A physician comments on excessive information.</ce:simple-para></ce:caption><ce:alt-text id="atte0055" role="short">Fig. 5.10</ce:alt-text><ce:source>(Alex Gregory/The New Yorker Collection/The Cartoon Bank.)</ce:source><ce:link id="ln0095" locator="f005-010-9780323552295" xlink:href="pii:B978032355229500005X/f005-010-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0060"><ce:label>Fig. 5.11</ce:label><ce:caption id="ca0100"><ce:simple-para id="sp0105" role="caption">Relationship between disease prevalence and predictive value in a test with 95% sensitivity and 95% specificity.</ce:simple-para></ce:caption><ce:alt-text id="atte0060" role="short">Fig. 5.11</ce:alt-text><ce:source>(From Mausner JS, Kramer S. <ce:italic>Mausner and Bahn Epidemiology: An Introductory Text</ce:italic>. Philadelphia: WB Saunders; 1985:221.)</ce:source><ce:link id="ln0115" locator="f005-011-9780323552295" xlink:href="pii:B978032355229500005X/f005-011-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0065"><ce:label>Fig. 5.12</ce:label><ce:caption id="ca0105"><ce:simple-para id="sp0110" role="caption">Maternal serum alpha-fetoprotein <ce:italic>(MSAPF)</ce:italic> distribution for singleton pregnancies at 15 to 20 weeks. The screen cutoff value of 2.5 multiples of the median is expected to result in a false-positive rate of up to 5% <ce:italic>(black hatched area)</ce:italic> and false-negative rates of up to 20% for spina bifida <ce:italic>(orange hatched area)</ce:italic> and 10% for anencephaly <ce:italic>(red hatched area)</ce:italic>.</ce:simple-para></ce:caption><ce:alt-text id="atte0065" role="short">Fig. 5.12</ce:alt-text><ce:source>(Modified from Prenatal diagnosis. In: Cunningham F, Leveno KJ, Bloom SL, et al, eds. <ce:italic>Williams Obstetrics</ce:italic>. 24th ed. New York: McGraw-Hill; 2013. <ce:inter-ref id="iw0010" xlink:href="http://accessmedicine.mhmedical.com.ezp.welch.jhmi.edu/content.aspx?bookid=1057&amp;sectionid=59789152">http://accessmedicine.mhmedical.com.ezp.welch.jhmi.edu/content.aspx?bookid=1057&amp;sectionid=59789152</ce:inter-ref>. Accessed June 19, 2017.)</ce:source><ce:link id="ln0120" locator="f005-012-9780323552295" xlink:href="pii:B978032355229500005X/f005-012-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0070"><ce:label>Fig. 5.13</ce:label><ce:caption id="ca0110"><ce:simple-para id="sp0125" role="caption">(A to D) Relationship of specificity to positive predictive value <ce:italic>(PPV)</ce:italic>.</ce:simple-para></ce:caption><ce:alt-text id="atte0070" role="short">Fig. 5.13</ce:alt-text><ce:source>(See explanation in the text under the subheading “<ce:cross-ref id="crf0270" refid="s0070">Relationship Between Positive Predictive Value and Specificity of the Test</ce:cross-ref>” on <ce:cross-ref id="crf9020" refid="s0070">page 109</ce:cross-ref>.)</ce:source><ce:link id="ln0125" locator="f005-013-9780323552295" xlink:href="pii:B978032355229500005X/f005-013-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0075"><ce:label>Fig. 5.14</ce:label><ce:caption id="ca0120"><ce:simple-para id="sp0135" role="caption">Endogenous circadian variation in blood pressure during the constant routine protocol. <ce:italic>DBP,</ce:italic> Diastolic blood pressure; <ce:italic>HR,</ce:italic> heart rate; <ce:italic>SBP,</ce:italic> systolic blood pressure.</ce:simple-para></ce:caption><ce:alt-text id="atte0075" role="short">Fig. 5.14</ce:alt-text><ce:source>(From Shea SA, Hilton MF, Hu K, et al. Existence of an endogenous circadian blood pressure rhythm in humans that peaks in the evening. <ce:italic>Circ Res</ce:italic>. 2011;108:980–984.)</ce:source><ce:link id="ln0140" locator="f005-014-9780323552295" xlink:href="pii:B978032355229500005X/f005-014-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0080"><ce:label>Fig. 5.15</ce:label><ce:caption id="ca0125"><ce:simple-para id="sp0140" role="caption">“This <ce:italic>is</ce:italic> a second opinion. At first, I thought you had something else.” One view of a second opinion.</ce:simple-para></ce:caption><ce:alt-text id="atte0080" role="short">Fig. 5.15</ce:alt-text><ce:source>(Leo Cullum/The New Yorker Collection/The Cartoon Bank.)</ce:source><ce:link id="ln0145" locator="f005-015-9780323552295" xlink:href="pii:B978032355229500005X/f005-015-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0085"><ce:label>Fig. 5.16</ce:label><ce:caption id="ca0135"><ce:simple-para id="sp0150" role="caption">Calculating the percent agreement between two observers. (A) Percent agreement when examining paired observations between observer 1 and observer 2. (B) Percent agreement when examining paired observations between observer 1 and observer 2, considering that cell d (agreement on the negatives) is very high. (C) Percent agreement when examining paired observations between observer 1 and observer 2, ignoring cell d. (D) Percent agreement when examining paired observations between observer 1 and observer 2, using only cells a, b, and c for the calculation.</ce:simple-para></ce:caption><ce:alt-text id="atte0085" role="short">Fig. 5.16</ce:alt-text><ce:link id="ln0155" locator="f005-016-9780323552295" xlink:href="pii:B978032355229500005X/f005-016-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0090"><ce:label>Fig. 5.17</ce:label><ce:caption id="ca0140"><ce:simple-para id="sp0155" role="caption">(A) Radiologic classification of breast density on synthetic 2D images as compared with digital 2D mammograms. (B) Percent agreement by synthetic and digital 2D mammograms. (C) Percent agreement by synthetic and digital 2D mammograms <ce:italic>expected by chance alone</ce:italic>.</ce:simple-para></ce:caption><ce:alt-text id="atte0090" role="short">Fig. 5.17</ce:alt-text><ce:source>(From Alshafeiy TI, Wadih A, Nicholson BT, et al. Comparison between digital and synthetic 2D mammograms in breast density interpretation. <ce:italic>AJR Am J Roentgenol</ce:italic>. 2017;209:W36–W41. Reprinted with permission from the American Journal of Roentgenology.)</ce:source><ce:link id="ln0180" locator="f005-017a-9780323552295" xlink:href="pii:B978032355229500005X/f005-017a-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:link id="ln0185" locator="f005-017b-9780323552295" xlink:href="pii:B978032355229500005X/f005-017b-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:link id="ln0190" locator="f005-017c-9780323552295" xlink:href="pii:B978032355229500005X/f005-017c-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0095"><ce:label>Fig. 5.18</ce:label><ce:caption id="ca0145"><ce:simple-para id="sp0160" role="caption">Graph of hypothetical test results that are reliable, but not valid.</ce:simple-para></ce:caption><ce:alt-text id="atte0095" role="short">Fig. 5.18</ce:alt-text><ce:link id="ln0210" locator="f005-018-9780323552295" xlink:href="pii:B978032355229500005X/f005-018-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0100"><ce:label>Fig. 5.19</ce:label><ce:caption id="ca0150"><ce:simple-para id="sp0165" role="caption">Graph of hypothetical test results that are valid, but not reliable.</ce:simple-para></ce:caption><ce:alt-text id="atte0100" role="short">Fig. 5.19</ce:alt-text><ce:link id="ln0215" locator="f005-019-9780323552295" xlink:href="pii:B978032355229500005X/f005-019-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:figure id="f0105"><ce:label>Fig. 5.20</ce:label><ce:caption id="ca0155"><ce:simple-para id="sp0170" role="caption">Graph of hypothetical test results that are both valid and reliable.</ce:simple-para></ce:caption><ce:alt-text id="atte0105" role="short">Fig. 5.20</ce:alt-text><ce:link id="ln0220" locator="f005-020-9780323552295" xlink:href="pii:B978032355229500005X/f005-020-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:figure><ce:table frame="topbot" id="t0010"><ce:label>TABLE 5.1</ce:label><ce:caption id="ca0020"><ce:simple-para id="sp0025" role="title">Calculation of the Sensitivity and Specificity of Screening Examinations</ce:simple-para></ce:caption><ce:alt-text id="atte0110" role="short">TABLE 5.1</ce:alt-text><ce:link id="ln0020" locator="t005-001-9780323552295" xlink:href="pii:B978032355229500005X/t005-001-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0015"><ce:label>TABLE 5.2</ce:label><ce:caption id="ca0025"><ce:simple-para id="sp0030" role="title">Comparison of the Results of a Dichotomous Test With Disease Status</ce:simple-para></ce:caption><ce:alt-text id="atte0115" role="short">TABLE 5.2</ce:alt-text><ce:link id="ln0025" locator="t005-002-9780323552295" xlink:href="pii:B978032355229500005X/t005-002-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0025"><ce:label>TABLE 5.3</ce:label><ce:caption id="ca0055"><ce:simple-para id="sp0060" role="title">Results of Screening With Test A</ce:simple-para></ce:caption><ce:alt-text id="atte0120" role="short">TABLE 5.3</ce:alt-text><ce:link id="ln0055" locator="t005-003-9780323552295" xlink:href="pii:B978032355229500005X/t005-003-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0030"><ce:label>TABLE 5.4</ce:label><ce:caption id="ca0065"><ce:simple-para id="sp0070" role="title">Results of Screening With Test B</ce:simple-para></ce:caption><ce:alt-text id="atte0125" role="short">TABLE 5.4</ce:alt-text><ce:link id="ln0065" locator="t005-004-9780323552295" xlink:href="pii:B978032355229500005X/t005-004-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0035"><ce:label>TABLE 5.5</ce:label><ce:caption id="ca0070"><ce:simple-para id="sp0075" role="title">Results of Screening With Test A</ce:simple-para></ce:caption><ce:alt-text id="atte0130" role="short">TABLE 5.5</ce:alt-text><ce:link id="ln0075" locator="t005-005-9780323552295" xlink:href="pii:B978032355229500005X/t005-005-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0040"><ce:label>TABLE 5.6</ce:label><ce:caption id="ca0080"><ce:simple-para id="sp0085" role="title">Results of Screening With Test B</ce:simple-para></ce:caption><ce:alt-text id="atte0135" role="short">TABLE 5.6</ce:alt-text><ce:link id="ln0085" locator="t005-006-9780323552295" xlink:href="pii:B978032355229500005X/t005-006-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0045"><ce:label>TABLE 5.7</ce:label><ce:caption id="ca0090"><ce:simple-para id="sp0095" role="title">Predictive Value of a Test</ce:simple-para></ce:caption><ce:alt-text id="atte0140" role="short">TABLE 5.7</ce:alt-text><ce:link id="ln0100" locator="t005-007-9780323552295" xlink:href="pii:B978032355229500005X/t005-007-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table><ce:table frame="topbot" id="t0050"><ce:label>TABLE 5.8</ce:label><ce:caption id="ca0095"><ce:simple-para id="sp0100" role="title">Relationship of Disease Prevalence to Positive Predictive Value</ce:simple-para></ce:caption><ce:alt-text id="atte0145" role="short">TABLE 5.8</ce:alt-text><tgroup cols="6"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><colspec colname="col3" colnum="3"/><colspec colname="col4" colnum="4"/><colspec colname="col5" colnum="5"/><colspec colname="col6" colnum="6"/><thead><row rowsep="1"><entry namest="col1" nameend="col6" align="center"><ce:small-caps>example: sensitivity = 99%, specificity = 95%</ce:small-caps></entry></row><row role="tcolhead1" rowsep="1"><entry align="left">Disease Prevalence</entry><entry align="left">Test Results</entry><entry align="left">Sick</entry><entry align="left">Not Sick</entry><entry align="left">Totals</entry><entry align="left">Positive Predictive Value</entry></row></thead><tbody><row rowsep="0"><entry morerows="2" align="left">1%</entry><entry align="left">+</entry><entry align="left">99</entry><entry align="left">495</entry><entry align="left">594</entry><entry morerows="2" align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0105" locator="if005-013-9780323552295" xlink:href="pii:B978032355229500005X/if005-013-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0150" role="short">Image 1</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">−</entry><entry align="left">1</entry><entry align="left">9,405</entry><entry align="left">9,406</entry></row><row rowsep="0"><entry align="left">Totals</entry><entry align="left">100</entry><entry align="left">9,900</entry><entry align="left">10,000</entry></row><row><entry morerows="2" align="left">5%</entry><entry rowsep="0" align="left">+</entry><entry rowsep="0" align="left">495</entry><entry rowsep="0" align="left">475</entry><entry rowsep="0" align="left">970</entry><entry morerows="2" align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0110" locator="if005-014-9780323552295" xlink:href="pii:B978032355229500005X/if005-014-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0155" role="short">Image 2</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">−</entry><entry align="left">5</entry><entry align="left">9,025</entry><entry align="left">9,030</entry></row><row><entry align="left">Totals</entry><entry align="left">500</entry><entry align="left">9,500</entry><entry align="left">10,000</entry></row></tbody></tgroup></ce:table><ce:table frame="topbot" id="t0055"><ce:label>TABLE 5.9</ce:label><ce:caption id="ca0115"><ce:simple-para id="sp0130" role="title">Relationship of Specificity to Positive Predictive Value</ce:simple-para></ce:caption><ce:alt-text id="atte0160" role="short">TABLE 5.9</ce:alt-text><tgroup cols="6"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><colspec colname="col3" colnum="3"/><colspec colname="col4" colnum="4"/><colspec colname="col5" colnum="5"/><colspec colname="col6" colnum="6"/><thead><row rowsep="1"><entry namest="col1" nameend="col6" align="center"><ce:small-caps>example: prevalence = 10%, sensitivity = 100%</ce:small-caps></entry></row><row role="tcolhead1" rowsep="1"><entry align="left">Specificity</entry><entry align="left">Test Results</entry><entry align="left">Sick</entry><entry align="left">Not Sick</entry><entry align="left">Totals</entry><entry align="left">Predictive Value</entry></row></thead><tbody><row rowsep="0"><entry morerows="2" align="left">70%</entry><entry align="left">+</entry><entry align="left">1,000</entry><entry align="left">2,700</entry><entry align="left">3,700</entry><entry morerows="2" align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0130" locator="if005-015-9780323552295" xlink:href="pii:B978032355229500005X/if005-015-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0165" role="short">Image 3</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">−</entry><entry align="left">0</entry><entry align="left">6,300</entry><entry align="left">6,300</entry></row><row rowsep="0"><entry align="left">Totals</entry><entry align="left">1,000</entry><entry align="left">9,000</entry><entry align="left">10,000</entry></row><row><entry morerows="2" align="left">95%</entry><entry rowsep="0" align="left">+</entry><entry rowsep="0" align="left">1,000</entry><entry rowsep="0" align="left">450</entry><entry rowsep="0" align="left">1,450</entry><entry morerows="2" align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0135" locator="if005-016-9780323552295" xlink:href="pii:B978032355229500005X/if005-016-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0170" role="short">Image 4</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">−</entry><entry align="left">0</entry><entry align="left">8,550</entry><entry align="left">8,550</entry></row><row><entry align="left">Totals</entry><entry align="left">1,000</entry><entry align="left">9,000</entry><entry align="left">10,000</entry></row></tbody></tgroup></ce:table><ce:table frame="topbot" id="t0060"><ce:label>TABLE 5.10</ce:label><ce:caption id="ca0130"><ce:simple-para id="sp0145" role="title">Observer or Instrument Variation: Percent Agreement</ce:simple-para></ce:caption><ce:alt-text id="atte0175" role="short">TABLE 5.10</ce:alt-text><ce:link id="ln0150" locator="t005-010-9780323552295" xlink:href="pii:B978032355229500005X/t005-010-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/></ce:table></ce:floats><ce:label>Chapter 5</ce:label><ce:title id="tit0010">Assessing the Validity and Reliability of Diagnostic and Screening Tests</ce:title><ce:keywords class="keyword" id="kwd9000" view="extended"><ce:section-title id="st9000">Keywords</ce:section-title><ce:keyword id="kw9000"><ce:text id="te9000">sensitivity</ce:text></ce:keyword><ce:keyword id="kw9005"><ce:text id="te9005">specificity</ce:text></ce:keyword><ce:keyword id="kw9010"><ce:text id="te9010">sequential (two-stage) and simultaneous testing</ce:text></ce:keyword><ce:keyword id="kw9015"><ce:text id="te9015">predictive value</ce:text></ce:keyword><ce:keyword id="kw9020"><ce:text id="te9020">reliability</ce:text></ce:keyword><ce:keyword id="kw9025"><ce:text id="te9025">percent agreement and kappa statistic</ce:text></ce:keyword><ce:keyword id="kw9030"><ce:text id="te9030">validity</ce:text></ce:keyword></ce:keywords><ce:displayed-quote id="dq0010"><ce:simple-para id="sp0010"><ce:italic>A normal individual is a person who has not been sufficiently examined.</ce:italic></ce:simple-para><ce:source>—Anonymous</ce:source></ce:displayed-quote><objectives><ce:section-title id="st0010">Learning Objectives</ce:section-title><ce:para id="p0010"><ce:list id="ulist0010"><ce:list-item id="u0010"><ce:label>•</ce:label><ce:para id="p0015">To define the validity and reliability of screening and diagnostic tests.</ce:para></ce:list-item><ce:list-item id="u0015"><ce:label>•</ce:label><ce:para id="p0020">To compare measures of validity, including sensitivity and specificity.</ce:para></ce:list-item><ce:list-item id="u0020"><ce:label>•</ce:label><ce:para id="p0025">To illustrate the use of multiple tests (sequential and simultaneous testing).</ce:para></ce:list-item><ce:list-item id="u0025"><ce:label>•</ce:label><ce:para id="p0030">To introduce positive and negative predictive value.</ce:para></ce:list-item><ce:list-item id="u0030"><ce:label>•</ce:label><ce:para id="p0035">To address measures of reliability, including percent agreement and kappa.</ce:para></ce:list-item></ce:list></ce:para></objectives><ce:sections><ce:para id="p0040">To understand how a disease is transmitted and develops and to provide appropriate and effective health care, it is necessary to distinguish between people in the population who have the disease and those who do not. This is an important challenge, both clinically, where patient care is the issue, and in the public health arena, where secondary prevention programs involving early disease detection through screening and interventions are fielded and where etiologic studies are conducted to provide a basis for primary prevention, if possible. Thus the quality of screening and diagnostic tests is a critical issue. Regardless of whether the test is a physical examination, a chest x-ray, an electrocardiogram, or a blood or urine assay, the same issue arises: <ce:italic>How good is the test in identifying populations of people with and without the disease in question?</ce:italic> This chapter addresses the question of how we assess the quality of newly available screening and diagnostic tests to make reasonable decisions about their use and interpretation.</ce:para><ce:section id="s0010"><ce:section-title id="st0015">Biologic Variation of Human Populations</ce:section-title><ce:para id="p0045">In using a test to distinguish between individuals with normal and abnormal results, it is important to understand how characteristics are distributed in human populations.</ce:para><ce:para id="p0050"><ce:cross-ref id="crf0010" refid="f0010">Fig. 5.1</ce:cross-ref><ce:float-anchor refid="f0010"/> shows the distribution of newly reported confirmed cases of hepatitis C virus infection in Massachusetts for 2009. We can see that there are two peaks of hepatitis C virus infection cases among young adults and middle-aged persons. This type of distribution, in which there are two peaks, is called a <ce:italic>bimodal curve</ce:italic>. The bimodal distribution permits the identification of increased rates of <ce:italic>new cases</ce:italic> among these two distinct age groups, which could be related to different reasons. In this situation, there has been a dramatic increase in hepatitis among injection drug users, a practice associated with sharing of injection equipment that led to this bimodal distribution.</ce:para><ce:para id="p0055">In general, however, most human characteristics are not distributed bimodally. <ce:cross-ref id="crf0015" refid="f0015">Fig. 5.2</ce:cross-ref><ce:float-anchor refid="f0015"/> shows the distribution of achieved low-density lipoprotein cholesterol (LDL-C) in participants of a clinical trial to study the safety of intensively reducing LDL-C as compared with less intensive LDL-C level lowering in patients after acute coronary syndrome. In this figure, there is no bimodal curve; what we see is a <ce:italic>unimodal curve</ce:italic>—a single peak. Therefore if we want to separate those in the group who achieved a safe low level of LDL-C, a cutoff level of LDL-C must be set below which people are labeled as achieving the “safe low level” and above which they are not labeled as such. This study shows that there is no obvious level of LDL-C that should be a treatment target. Although we could choose a cutoff based on statistical considerations, as the authors in this study showed, we would ideally like to choose a cutoff on the basis of some biologic information—that is, we would want to know that an intensive LDL-C lowering strategy below the chosen cutoff level is associated with increased risk of subsequent treatment side effects; adverse muscle, hepatobiliary, and neurocognitive events; or disease complications; hemorrhagic stroke, heart failure, cancer, and noncardiovascular death. Unfortunately, for many human characteristics, we do not have such information to serve as a guide in setting this level.</ce:para><ce:para id="p0060">In either distribution—unimodal or bimodal—it is usually easy to distinguish between the extreme values of abnormal and normal. With either type of curve, however, uncertainty remains about cases that fall into the gray zone.</ce:para></ce:section><ce:section id="s0015"><ce:section-title id="st0020">Validity of Screening Tests</ce:section-title><ce:para id="p0065">The <ce:italic>validity</ce:italic> of a test is defined as its ability to distinguish between who has a disease and who does not. Validity has two components: sensitivity and specificity. The <ce:italic>sensitivity</ce:italic> of the test is defined as the ability of the test to identify correctly those who <ce:italic>have</ce:italic> the disease. The <ce:italic>specificity</ce:italic> of the test is defined as the ability of the test to identify correctly those who <ce:italic>do not have</ce:italic> the disease.</ce:para><ce:section id="s0020"><ce:section-title id="st0025">Tests With Dichotomous Results (Positive or Negative)</ce:section-title><ce:para id="p0070">Suppose we have a hypothetical population of 1,000 people, of whom 100 have a certain disease and 900 do not. A test is available that gives either positive or negative results. We want to use this test to distinguish persons who have the disease from those who do not. The results obtained by applying the test to this population of 1,000 people are shown in <ce:cross-ref id="crf0020" refid="t0010">Table 5.1</ce:cross-ref><ce:float-anchor refid="t0010"/>.</ce:para><ce:para id="p0075">How good was the test? First, how good was the test in correctly identifying those who had the disease? <ce:cross-ref id="crf0025" refid="t0010">Table 5.1</ce:cross-ref> indicates that of the 100 people with the disease, 80 were correctly identified as “positive” by the test, and a positive identification was missed in 20. Thus the <ce:italic>sensitivity</ce:italic> of the test, which is defined as the proportion of diseased people who were correctly identified as “positive” by the test, is 80/100, or 80%.</ce:para><ce:para id="p0080">Second, how good was the test in correctly identifying those who did not have the disease? Looking again at <ce:cross-ref id="crf0030" refid="t0010">Table 5.1</ce:cross-ref>, of the 900 people who did not have the disease, the test correctly identified 800 as “negative.” The <ce:italic>specificity</ce:italic> of the test, which is defined as the proportion of nondiseased people who are correctly identified as “negative” by the test, is therefore 800/900, or 89%.</ce:para><ce:para id="p0085">To calculate the sensitivity and specificity of a test, we must know who “really” has the disease and who “does not” from a source other than the test we are using. We are, in fact, comparing our test results with some gold standard—an external source of “truth” regarding the disease status of each individual in the population. Sometimes this truth may be the result of another test that has been in use, and sometimes it is the result of a more definitive, and often more invasive, test (e.g., tumor biopsy, cardiac catheterization, or tissue biopsy). However, in real life, when we use a test to identify diseased and nondiseased persons in a population, we clearly do not know who has the disease and who does not. (If this were already established, testing would be pointless.) But to quantitatively assess the sensitivity and specificity of a test, we must have another source of truth with which to compare the test results.</ce:para><ce:para id="p0090"><ce:cross-ref id="crf0035" refid="t0015">Table 5.2</ce:cross-ref><ce:float-anchor refid="t0015"/> compares the results of a dichotomous test (results are unambiguously either positive or negative) with the actual disease status. Ideally, we would like all of the tested subjects to fall into the two cells shown in the upper left and lower right on the table: people with the disease who are correctly called “positive” by the test <ce:italic>(true positives)</ce:italic> and people without the disease who are correctly called “negative” by the test <ce:italic>(true negatives)</ce:italic>. Unfortunately, such is rarely if ever the case. Some people who do not have the disease are erroneously called “positive” by the test <ce:italic>(false positives)</ce:italic>, and some people with the disease are erroneously called “negative” <ce:italic>(false negatives)</ce:italic>.</ce:para><ce:para id="p0095">Why are these issues important? When we conduct a screening program, we often have a large group of people who screened positive, including both people who really have the disease <ce:italic>(true positives)</ce:italic> and people who do not have the disease <ce:italic>(false positives)</ce:italic>. The issue of <ce:italic>false positives</ce:italic> is important because all people who screened positive are brought back for more sophisticated and more expensive tests or perhaps undergo an invasive procedure that is not necessary. Of the several problems that result, the first is a burden on the health care system. Another is the anxiety and worry induced in persons who have been told that they have tested positive. Considerable evidence indicates that many people who are labeled “positive” by a screening test never have that label completely erased, even if the results of a subsequent evaluation are negative. For example, children labeled “positive” in a screening program for heart disease may be handled as handicapped by parents and school personnel even after being told that subsequent more definitive tests were negative. In addition, such individuals may be limited in regard to employment and insurability by erroneous interpretation of positive screening test results, even if subsequent tests fail to substantiate any positive finding.</ce:para><ce:para id="p0100">Why is the problem of <ce:italic>false negatives</ce:italic> important? If a person has the disease but is erroneously informed that the test result is negative, and if the disease is a serious one for which effective intervention is available, the problem is indeed critical. For example, if the disease is a type of cancer that is curable only in its early stages, a false-negative result could represent a virtual death sentence. Thus the importance of false-negative results depends on the nature and severity of the disease being screened for, the effectiveness of available intervention measures, and whether the effectiveness is greater if the intervention is administered early in the natural history of the disease.</ce:para></ce:section><ce:section id="s0025"><ce:section-title id="st0030">Tests of Continuous Variables</ce:section-title><ce:para id="p0105">So far we have discussed a test with only two possible results: positive or negative. But we often test for a continuous variable, such as blood pressure or blood glucose level, for which there is no obvious “positive” or “negative” result. A decision must therefore be made in establishing a cutoff level above which a test result is considered positive and below which a result is considered negative. Let's consider the diagrams shown in <ce:cross-ref id="crf0040" refid="f0020">Fig. 5.3</ce:cross-ref><ce:float-anchor refid="f0020"/>.</ce:para><ce:para id="p0110"><ce:cross-ref id="crf0050" refid="f0020">Fig. 5.3A</ce:cross-ref> shows a population of 20 diabetics and 20 nondiabetics who are being screened using a blood sugar test whose scale is shown along the vertical axis from high to low. The diabetics are represented by blue circles and the nondiabetics by red circles. We see that although blood sugar levels tend to be higher in diabetics than in nondiabetics, no level clearly separates the two groups; there is some overlap of diabetics and nondiabetics at every blood sugar level. Nevertheless, we must select a cutoff point so that those whose results fall above the cutoff can be called “positive,” and can be called back for further testing, and those whose results fall below that point are called “negative,” and are not called back for further testing.</ce:para><ce:para id="p0115">Suppose a relatively high cutoff level is chosen (see <ce:cross-ref id="crf0055" refid="f0020">Fig. 5.3B</ce:cross-ref>). Clearly, many of the diabetics will not be identified as positive; on the other hand, most of the nondiabetics will be correctly identified as negative. If these results are distributed on a 2 × 2 table, the sensitivity of the test using this cutoff level will be 25% (5/20) and the specificity will be 90% (18/20). So, most of the diabetics will not be detected, but most of the nondiabetics will be correctly classified.</ce:para><ce:para id="p0120">What if a low cutoff level is chosen (see <ce:cross-ref id="crf0060" refid="f0020">Fig. 5.3C</ce:cross-ref>)? Very few diabetics would be misdiagnosed. What, then, is the problem? A large proportion of the nondiabetics are now identified as positive by the test. As seen in the 2 × 2 table, the sensitivity is now 85% (17/20), but the specificity is only 30% (6/20).</ce:para><ce:para id="p0125">The difficulty is that in the real world, no vertical line separates the diabetics and nondiabetics, and they are indeed mixed together (see <ce:cross-ref id="crf0065" refid="f0020">Fig. 5.3D</ce:cross-ref>); in fact, they are not even distinguishable by red or blue circles (see <ce:cross-ref id="crf0070" refid="f0020">Fig. 5.3E</ce:cross-ref>). So if a high cutoff level is used (see <ce:cross-ref id="crf0075" refid="f0020">Fig. 5.3F</ce:cross-ref>), all those with results below the line will be assured they do not have the disease and will not be followed further; if the low cutoff is used (see <ce:cross-ref id="crf0080" refid="f0020">Fig. 5.3G</ce:cross-ref>), all those with results above the line will be brought back for further testing.</ce:para><ce:para id="p0130"><ce:cross-ref id="crf0085" refid="f0025">Fig. 5.4A</ce:cross-ref><ce:float-anchor refid="f0025"/> shows actual data from a historical report regarding the distribution of blood sugar levels in diabetics and nondiabetics. Suppose we were to screen this population. If we decide to set the cutoff level so that we identify all of the diabetics (100% sensitivity), we could set the level at 80 mg/dL (see <ce:cross-ref id="crf0095" refid="f0025">Fig. 5.4B</ce:cross-ref>). The problem is, however, that in so doing we will also call many of the nondiabetics positive—that is, the specificity will be very low. On the other hand, if we set the level at 200 mg/dL (see <ce:cross-ref id="crf0100" refid="f0025">Fig. 5.4C</ce:cross-ref>) so that we call all the nondiabetics negative (100% specificity), we now miss many of the true diabetics because the sensitivity will be very low. Thus there is a trade-off between sensitivity and specificity: if we increase the sensitivity by lowering the cutoff level, we decrease the specificity; if we increase the specificity by raising the cutoff level, we decrease the sensitivity. To quote an unknown sage: “There is no such thing as a free lunch.”</ce:para><ce:para id="p0135">The dilemma involved in deciding whether to set a high cutoff or a low cutoff rests in the problem of the false positives and the false negatives that result from the testing. It is important to remember that in screening we end up with groups classified only on the basis of the results of their screening tests, either positive or negative. We have no information regarding their true disease status, which, of course, is the reason for carrying out the screening. In effect, the results of the screening test yield not four groups, as seen in <ce:cross-ref id="crf0105" refid="f0030">Fig. 5.5</ce:cross-ref><ce:float-anchor refid="f0030"/>, but rather two groups: one group of people who tested positive and one group who tested negative. Those who tested positive will be notified of their test result and will be asked to return for additional examinations. The other group, who tested negative, will be notified that their test result was negative and will therefore not be asked to return for further testing (<ce:cross-ref id="crf0110" refid="f0035">Fig. 5.6</ce:cross-ref><ce:float-anchor refid="f0035"/>).</ce:para><ce:para id="p0140">The choice of a high or a low cutoff level for screening therefore depends on the importance we attach to false positives and false negatives. False positives are associated with costs—emotional and financial—as well as with the difficulty of “delabeling” a person who tests positive and is later found not to have the disease. In addition, false-positive results may pose a major burden to the health care system, in that a large group of people need to be brought back for a retest, when only a few of them may have the disease. Those with false-negative results, on the other hand, will be told they do not have the disease and will not be followed, so a serious disease might possibly be missed at an early treatable stage. Thus the choice of cutoff level relates to the relative importance of false positivity and false negativity for the disease in question.</ce:para></ce:section></ce:section><ce:section id="s0030"><ce:section-title id="st0035">Use of Multiple Tests</ce:section-title><ce:para id="p0145">Often more than one screening test may be applied in the same individuals to detect an illness—either sequentially (one after another) or simultaneously (both conducted at the same time). The results of these approaches are described in this section.</ce:para><ce:section id="s0035"><ce:section-title id="st0040">Sequential (Two-Stage) Testing</ce:section-title><ce:para id="p0150">In sequential (or two-stage) screening, a less expensive, less invasive, or less uncomfortable test is generally performed first, and those who screen positive are recalled for further testing with a more expensive, more invasive, or more uncomfortable test, which may have greater sensitivity and specificity. It is hoped that bringing back for further testing only those who screen positive will reduce the problem of false positives.</ce:para><ce:para id="p0155">Consider the hypothetical example in <ce:cross-ref id="crf0115" refid="f0040">Fig. 5.7A</ce:cross-ref><ce:float-anchor refid="f0040"/>, in which a population is screened for diabetes using a test with a sensitivity of 70% and a specificity of 80%. How are the data shown in this table obtained? The disease prevalence in this population is given as 5%, so that in the population of 10,000, 500 persons have the disease. With a sensitivity of 70%, the test will correctly identify 350 of the 500 people who have the disease. With a specificity of 80%, the test will correctly identify as nondiabetic 7,600 of the 9,500 people who are free of diabetes; however, 1,900 of these 9,500 will have positive results. Thus a total of 2,250 people will test positive and will be brought back for a second test. (Remember that in real life we do not have the vertical line separating diabetics and nondiabetics, and we do not know that only 350 of the 2,250 have diabetes.)</ce:para><ce:para id="p0160">Now those 2,250 people are brought back and screened using a second test (such as a glucose tolerance test), which, for purposes of this example, is assumed to have a sensitivity of 90% and a specificity of 90%. <ce:cross-ref id="crf0125" refid="f0040">Fig. 5.7B</ce:cross-ref> shows test 1 together with test 2, which deals only with the 2,250 people who tested positive in the first screening test and have been brought back for second-stage screening.</ce:para><ce:para id="p0165">Since 350 people (of the 2,250) have the disease and the test has a sensitivity of 90%, 315 of those 350 will be correctly identified as positive. Because 1,900 (of the 2,250) do not have diabetes and the test specificity is 90%, 1,710 of the 1,900 will be correctly identified as negative and 190 will be false positives.</ce:para><ce:para id="p0170">We are now able to calculate the <ce:italic>net sensitivity</ce:italic> and the <ce:italic>net specificity</ce:italic> of using both tests in sequence. After finishing both tests, 315 people of the total 500 people with diabetes in this population of 10,000 will have been correctly called positive: 315/500 = 63% <ce:italic>net sensitivity</ce:italic> (which can also be calculated by multiplying the sensitivity of the first test times the sensitivity of the second test; i.e., 0.70 × 0.90 = 0.63). Thus there is a loss in net sensitivity by using both tests sequentially. To calculate <ce:italic>net specificity</ce:italic>, note that 7,600 people of the 9,500 in this population who do not have diabetes were correctly called negative in the first-stage screening and were not tested further; an additional 1,710 of those 9,500 nondiabetics were correctly called negative in the second-stage screening. Thus a total of 7,600 + 1,710 of the 9,500 nondiabetics were correctly called negative: 9,310/9,500 = 98% <ce:italic>net specificity</ce:italic>. Thus use of both tests in sequence has resulted in a gain in <ce:italic>net specificity</ce:italic>.</ce:para></ce:section><ce:section id="s0040"><ce:section-title id="st0045">Simultaneous Testing</ce:section-title><ce:para id="p0175">Let's now turn to the use of simultaneous tests. We assume that in a population of 1,000 people, the prevalence of a disease is 20%. Therefore 200 people have the disease, but we do not know who they are. In order to identify the 200 people who have this disease, we screen this population of 1,000 using two tests for this disease, test A and test B, at the same time. We assume that the sensitivity and specificity of the two tests are as follows:<ce:display><ce:table frame="topbot" id="t0020"><ce:alt-text id="atte0180" role="short">Unlabelled table</ce:alt-text><tgroup cols="2"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><thead><row rowsep="0"><entry align="left">Test A</entry><entry align="left">Test B</entry></row></thead><tbody><row rowsep="0"><entry align="left">Sensitivity = 80%</entry><entry align="left">Sensitivity = 90%</entry></row><row><entry align="left">Specificity = 60%</entry><entry align="left">Specificity = 90%</entry></row></tbody></tgroup></ce:table></ce:display></ce:para></ce:section><ce:section id="s0045"><ce:section-title id="st0050">Net Sensitivity Using Two Simultaneous Tests</ce:section-title><ce:para id="p0180">The first question we ask is, “What is the <ce:italic>net sensitivity</ce:italic> using test A and test B <ce:italic>simultaneously</ce:italic>?” To be considered positive and therefore included in the numerator for net sensitivity for two tests used simultaneously, a person must be identified as positive by test A, test B, or both tests.</ce:para><ce:para id="p0185">To calculate net sensitivity, let's first consider the results of screening with test A whose sensitivity is 80%: of the 200 people who have the disease, 160 test positive (<ce:cross-ref id="crf0130" refid="t0025">Table 5.3</ce:cross-ref><ce:float-anchor refid="t0025"/>). In <ce:cross-ref id="crf0135" refid="f0045">Fig. 5.8A</ce:cross-ref><ce:float-anchor refid="f0045"/>, the oval represents the 200 people who have the disease. In <ce:cross-ref id="crf0145" refid="f0045">Fig. 5.8B</ce:cross-ref> the pink circle within the oval represents the 160 who test positive with test A. These 160 are the true positives using test A.</ce:para><ce:para id="p0190">Consider next the results of screening with test B whose sensitivity is 90% (<ce:cross-ref id="crf0150" refid="t0030">Table 5.4</ce:cross-ref><ce:float-anchor refid="t0030"/>). Of the 200 people who have the disease, 180 test positive by test B. In <ce:cross-ref id="crf0155" refid="f0045">Fig. 5.8C</ce:cross-ref>, the oval again represents the 200 people who have the disease. The blue circle within the oval represents the 180 who test positive with test B. These 180 are the true positives using test B.</ce:para><ce:para id="p0195">In order to calculate the numerator for net sensitivity, we cannot just add the number of persons who tested positive using test A to those who tested positive using test B because some people tested positive on both tests. These people are shown in lavender by the overlapping area of the two circles, and we do not want to count them twice (see <ce:cross-ref id="crf0160" refid="f0045">Fig. 5.8D</ce:cross-ref>). How do we determine how many people tested positive on both tests?</ce:para><ce:para id="p0200">Test A has a sensitivity of 80% and thus identifies as positive 80% of the 200 who have the disease (160 people). Test B has a sensitivity of 90%. Therefore it identifies as positive 90% of the same 160 people who are identified by test A (144 people). Thus when tests A and B are used simultaneously, 144 people are identified as positive by both tests (see <ce:cross-ref id="crf0165" refid="f0045">Fig. 5.8E</ce:cross-ref>).</ce:para><ce:para id="p0205">Recall that test A correctly identified 160 people with the disease as positive. Because 144 of them were identified by both tests, 160 − 144, or 16 people, were correctly identified <ce:italic>only</ce:italic> by test A.</ce:para><ce:para id="p0210">Test B correctly identified 180 of the 200 people with the disease as positive. Because 144 of them were identified by both tests, 180 − 144, or 36 people, were correctly identified <ce:italic>only</ce:italic> by test B. Thus as seen in <ce:cross-ref id="crf0170" refid="f0045">Fig. 5.8F</ce:cross-ref>, using tests A and B simultaneously,<ce:display><ce:formula id="e0010"><mml:math altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mtext>Net sensitivity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>16</mml:mn><mml:mo>+</mml:mo><mml:mn>144</mml:mn><mml:mo>+</mml:mo><mml:mn>36</mml:mn></mml:mrow><mml:mrow><mml:mn>200</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>196</mml:mn></mml:mrow><mml:mrow><mml:mn>200</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>98</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:section><ce:section id="s0050"><ce:section-title id="st0055">Net Specificity Using Two Simultaneous Tests</ce:section-title><ce:para id="p0215">The next question is, “What is the <ce:italic>net specificity</ce:italic> using test A and test B <ce:italic>simultaneously</ce:italic>?” To be included in the numerator for net specificity for two tests used simultaneously, a person must be identified as <ce:italic>negative by both tests</ce:italic>. In order to calculate the numerator for net specificity, we therefore need to determine how many people had negative results on both tests. How do we do this?</ce:para><ce:para id="p0220">Test A has a specificity of 60% and thus correctly identifies 60% of the 800 who do not have the disease (480 people; <ce:cross-ref id="crf0175" refid="t0035">Table 5.5</ce:cross-ref><ce:float-anchor refid="t0035"/>). In <ce:cross-ref id="crf0180" refid="f0050">Fig. 5.9A</ce:cross-ref><ce:float-anchor refid="f0050"/>, the oval represents the 800 people who do not have the disease. The green circle within the oval in <ce:cross-ref id="crf0190" refid="f0050">Fig. 5.9B</ce:cross-ref> represents the 480 people who test negative with test A. These are the true negatives using test A.</ce:para><ce:para id="p0225">Test B has a specificity of 90% and thus identifies as negative 90% of the 800 people who do not have the disease (720 people; <ce:cross-ref id="crf0195" refid="t0040">Table 5.6</ce:cross-ref><ce:float-anchor refid="t0040"/> and the yellow circle in <ce:cross-ref id="crf0200" refid="f0050">Fig. 5.9C</ce:cross-ref>). However, to be called negative in simultaneous tests, only people who test negative on both tests are considered to have had negative results (see <ce:cross-ref id="crf0205" refid="f0050">Fig. 5.9D</ce:cross-ref>). These people are shown in light green by the overlapping area of the two circles. Test B also identifies as negative 90% of the same 480 people identified as negative by test A (432 people). Thus, as shown by the overlapping circles, when tests A and B are used simultaneously, 432 people are identified as negative by both tests (see <ce:cross-ref id="crf0210" refid="f0050">Fig. 5.9E</ce:cross-ref>). Thus when tests A and B are used simultaneously (see <ce:cross-ref id="crf0215" refid="f0050">Fig. 5.9F</ce:cross-ref>),<ce:display><ce:formula id="e0015"><mml:math altimg="si2.gif" overflow="scroll"><mml:mrow><mml:mtext>Net specificity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>432</mml:mn></mml:mrow><mml:mrow><mml:mn>800</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>54</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0230">Therefore when two simultaneous tests are used, there is a net gain in sensitivity (from 80% using test A and 90% using test B to 98% using both tests simultaneously). However, there is a net loss in specificity (net specificity = 54%) compared with using either test alone (specificity of 60% using test A and 90% using test B).</ce:para></ce:section><ce:section id="s0055"><ce:section-title id="st0060">Comparison of Simultaneous and Sequential Testing</ce:section-title><ce:para id="p0235">In a clinical setting, multiple tests are often used simultaneously. For example, a patient admitted to a hospital may have an array of tests performed at the time of admission. When multiple tests are used simultaneously to detect a specific disease, the individual is generally considered to have tested “positive” if he or she has a positive result on <ce:italic>any</ce:italic> one or more of the tests. The individual is considered to have tested “negative” if he or she tests negative on <ce:italic>all</ce:italic> of the tests. The effects of such a testing approach on sensitivity and specificity differ from those that result from sequential testing. In sequential testing, when we retest those who tested positive on the first test, there is a loss in net sensitivity and a gain in net specificity. In simultaneous testing, because an individual who tests positive on <ce:italic>any</ce:italic> one or multiple tests is considered positive, there is a gain in net sensitivity. However, to be considered negative, a person would have to test negative on <ce:italic>all</ce:italic> the tests performed. As a result, there is a loss in net specificity.</ce:para><ce:para id="p0240">In summary, as we have seen previously, when two sequential tests are used and those who test positive by the first test are brought in for the second test, there is a net loss in sensitivity, but a net gain in specificity, compared with either test alone. However, when two simultaneous tests are used, there is a net gain in sensitivity and a net loss in specificity, compared with either test alone.</ce:para><ce:para id="p0245">Given these results, the decision to use either sequential or simultaneous testing often is based both on the objectives of the testing, including whether testing is being done for screening or diagnostic purposes, and on practical considerations related to the setting in which the testing is being done, including the length of hospital stay, costs, and degree of invasiveness of each of the tests, as well as the extent of third-party insurance coverage. <ce:cross-ref id="crf0220" refid="f0055">Fig. 5.10</ce:cross-ref><ce:float-anchor refid="f0055"/> shows a physician dealing with perceived information overload.</ce:para></ce:section></ce:section><ce:section id="s0060"><ce:section-title id="st0065">Predictive Value of a Test</ce:section-title><ce:para id="p0250">So far we have asked, “How good is the test at identifying people with the disease and people without the disease?” This is an important issue, particularly in screening free-living populations who have no symptoms of the disease being evaluated. In effect, we are asking, “If we screen a population, what proportion of people who have the disease will be correctly identified?” This is clearly an important public health consideration. In the clinical setting, however, a different question may be important for the clinician: If the test results are positive in this patient, what is the probability that this patient has the disease? This is called the <ce:italic>positive predictive value</ce:italic> (PPV) of the test. In other words, what proportion of patients who test positive actually have the disease in question? To calculate the PPV, we divide the number of true positives by the total number who tested positive (true positives + false positives).</ce:para><ce:para id="p0255">Let's return to the example shown in <ce:cross-ref id="crf0225" refid="t0010">Table 5.1</ce:cross-ref>, in which a population of 1,000 persons is screened. As seen in <ce:cross-ref id="crf0230" refid="t0045">Table 5.7</ce:cross-ref><ce:float-anchor refid="t0045"/>, a 2 × 2 table shows the results of a dichotomous screening test in that population. Of the 1,000 subjects, 180 have a positive test result; of these 180 subjects, 80 have the disease. Therefore the PPV is 80/180, or 44%.</ce:para><ce:para id="p0260">A parallel question can be asked about negative test results: “If the test result is negative, what is the probability that this patient does not have the disease?” This is called the <ce:italic>negative predictive value</ce:italic> (NPV) of the test. It is calculated by dividing the number of true negatives by all those who tested negative (true negatives + false negatives). Looking again at the example in <ce:cross-ref id="crf0235" refid="t0045">Table 5.7</ce:cross-ref>, 820 people have a negative test result, and of these, 800 do not have the disease. Thus the NPV is 800/820, or 98%.</ce:para><ce:para id="p0265">Every test that a clinician performs—history, physical examination, laboratory tests, x-rays, electrocardiograms, and other procedures—is used to enhance the likelihood of making the correct diagnosis. What he or she wants to know after administering a test to a patient is: “Given this positive test result, what is the likelihood that the patient has the disease?”</ce:para><ce:para id="p0270">Unlike the sensitivity and specificity of the test, which can be considered characteristic of the test being used, the PPV is affected by two factors: the <ce:italic>prevalence</ce:italic> of the disease in the population tested and, when the disease is infrequent, the <ce:italic>specificity</ce:italic> of the test being used. Both of these relationships are discussed in the following sections.</ce:para><ce:section id="s0065"><ce:section-title id="st0070">Relationship Between Positive Predictive Value and Disease Prevalence</ce:section-title><ce:para id="p0275">In the discussion of predictive value that follows, the term <ce:italic>predictive value</ce:italic> is used to denote the <ce:italic>positive</ce:italic> predictive value of the test.</ce:para><ce:para id="p0280">The relationship between predictive value and <ce:italic>disease prevalence</ce:italic> can be seen in the example given in <ce:cross-ref id="crf0240" refid="t0050">Table 5.8</ce:cross-ref><ce:float-anchor refid="t0050"/>. First, let's direct our attention to the upper part of the table. Assume that we are using a test with a sensitivity of 99% and a specificity of 95% in a population of 10,000 people in which the disease prevalence is 1%. Because the prevalence is 1%, 100 of the 10,000 persons have the disease and 9,900 do not. With a sensitivity of 99%, the test correctly identifies 99 of the 100 people who have the disease. With a specificity of 95%, the test correctly identifies as negative 9,405 of the 9,900 people who do not have the disease. Thus, in this population with a 1% prevalence, 594 people are identified as positive by the test (99 + 495). However, of these 594 people, 495 (83%) are false positives and the PPV is therefore 99/594, or only 17%.</ce:para><ce:para id="p0285">Let's now apply the same test—with the same sensitivity and specificity—to a population with a higher disease prevalence, 5%, as seen in the lower part of <ce:cross-ref id="crf0245" refid="t0050">Table 5.8</ce:cross-ref>. Using calculations similar to those used in the upper part of the table, the PPV is now 51%. Thus the higher prevalence in the screened population has led to a marked increase in the PPV using the same test. <ce:cross-ref id="crf0250" refid="f0060">Fig. 5.11</ce:cross-ref><ce:float-anchor refid="f0060"/> shows the relationship between disease prevalence and predictive value from a classic example. Clearly most of the gain in predictive value occurs with increases in prevalence at the lowest rates of disease prevalence.</ce:para><ce:para id="p0290">Why should we be concerned about the relationship between predictive value and disease prevalence? As we have seen, the higher the prevalence, the higher the predictive value. Therefore a screening program is most productive and more cost-effective if it is directed to a high-risk target population. Screening a total population for a relatively infrequent disease can be a wasteful use of resources and may yield few previously undetected cases relative to the amount of effort involved. However, if a high-risk subset can be identified and screening can be directed to this group, the program is likely to be far more productive. In addition, a high-risk population may be more motivated to participate in such a screening program and more likely to take recommended action if their screening results are positive.</ce:para><ce:para id="p0295">The relationship between predictive value and disease prevalence also shows that the results of any test must be interpreted in the context of the prevalence of the disease in the population from which the subject originates. An interesting example is seen with the measurement of the maternal serum α-fetoprotein (MSAFP) level for prenatal diagnosis of spina bifida. <ce:cross-ref id="crf0255" refid="f0065">Fig. 5.12</ce:cross-ref><ce:float-anchor refid="f0065"/> shows the distribution of MSAFP levels in normal unaffected pregnancies and in pregnancies in which the fetus has Down syndrome; spina bifida, which is a neural tube defect; or anencephaly. For the purpose of this example, we will focus on the curves for unaffected pregnancies and spina bifida. Although the distribution of these two curves is bimodal, there is a range in which the curves overlap, and within that range, it may not always be clear to which curve the mother and fetus belong. If MSAFP is in the higher range for an unaffected pregnancy, the true prevalence of spina bifida will be low for the same range. Thus such overlap in the MSAFP in the unaffected pregnancies and those with fetuses with spina bifida has led to the test having a very low PPV, of only 2% to 6%.<ce:cross-ref id="crf0260" refid="bib1"><ce:sup loc="post">1</ce:sup></ce:cross-ref></ce:para><ce:para id="p0300">It is possible that the same test can have a very different predictive value when it is administered to a high-risk (high prevalence) population or to a low-risk (low prevalence) population. This has clear clinical implications: A woman may make a decision to terminate a pregnancy, and a physician may formulate advice to such a woman on the basis of the test results. However, the same test result may be interpreted differently, depending on whether the woman comes from a pool of high-risk or low-risk women, which will be reflected in the PPV of the test. Consequently, by itself, the test result may not be sufficient to serve as a guide without taking into account the other considerations just described.</ce:para><ce:para id="p0305">The following true examples highlight the importance of this issue:</ce:para><ce:para id="p0310"><ce:displayed-quote id="dq0015"><ce:simple-para id="sp0115"><ce:italic>The head of a firefighters’ union consulted a university cardiologist because the fire department physician had read an article in a leading medical journal reporting that a certain electrocardiographic finding was highly predictive of serious, generally unrecognized, coronary heart disease. On the basis of this article, the fire department physician was disqualifying many young, able-bodied firefighters from active duty. The cardiologist read the paper and found that the study had been carried out in hospitalized patients.</ce:italic></ce:simple-para></ce:displayed-quote></ce:para><ce:para id="p0315">What was the problem? Because hospitalized patients have a much higher prevalence of heart disease than does a group of young, able-bodied firefighters, the fire department physician had erroneously taken the high predictive value obtained in studying a high-prevalence population and inappropriately applied it to a low-prevalence population of healthy firefighters, in whom the same test would actually have a much lower predictive value.</ce:para><ce:para id="p0320">Here is another example:</ce:para><ce:para id="p0325"><ce:displayed-quote id="dq0020"><ce:simple-para id="sp0120"><ce:italic>A physician visited his general internist for a regular annual medical examination, which included a stool examination for occult blood. One of the three stool specimens examined in the test was positive. The internist told his physician-patient that the result was of no significance because he regularly encountered many false-positive test results in his busy practice. The test was repeated on three new stool specimens, and all three of the new specimens were now negative. Nevertheless, sensing his patient's lingering concerns, the internist referred his physician-patient to a gastroenterologist. The gastroenterologist said, “In my experience, the positive stool finding is serious. Such a finding is almost always associated with pathologic gastrointestinal disorders. The subsequent negative test results mean nothing, because you could have a tumor that only bleeds intermittently.”</ce:italic></ce:simple-para></ce:displayed-quote></ce:para><ce:para id="p0330">Who was correct in this episode? The answer is that both the general internist and the gastroenterologist were correct. The internist gave his assessment of predictive value based on his experience in his general medical practice—a population with a low prevalence of serious gastrointestinal disease. On the other hand, the gastroenterologist gave his assessment of the predictive value of the test based on his experience in his referral practice—a practice in which most patients are referred because of a likelihood of serious gastrointestinal illness, a high-prevalence population.</ce:para></ce:section><ce:section id="s0070"><ce:section-title id="st0075">Relationship Between Positive Predictive Value and Specificity of the Test</ce:section-title><ce:para id="p0335">In the discussion that follows, the term <ce:italic>predictive value</ce:italic> is used to denote the PPV of the test.</ce:para><ce:para id="p0340">A second factor that affects the predictive value of a test is the <ce:italic>specificity</ce:italic> of the test. Examples of this are shown first in graphical form and then in tabular form. <ce:cross-ref id="crf0265" refid="f0070">Fig. 5.13A to D</ce:cross-ref><ce:float-anchor refid="f0070"/> diagrams the results of screening a population; however, the 2 × 2 tables in these figures differ from those shown in earlier figures. Each cell is drawn with its size proportional to the population it represents. In each figure the cells that represent persons who tested positive are shaded blue; these are the cells that will be used in calculating the PPV.</ce:para><ce:para id="p0345"><ce:cross-ref id="crf0275" refid="f0070">Fig. 5.13A</ce:cross-ref> presents the baseline screened population that is used in our discussion: a population of 1,000 people in whom the prevalence is 50%; thus 500 people have the disease and 500 do not. In analyzing this figure, we also assume that the screening test that was used has a sensitivity of 50% and a specificity of 50%. Because 500 people tested positive, and 250 of these have the disease, the predictive value is 250/500, or 50%.</ce:para><ce:para id="p0350">Fortunately, the prevalence of most diseases is much lower than 50%; we are generally dealing with relatively infrequent diseases. Therefore <ce:cross-ref id="crf0280" refid="f0070">Fig. 5.13B</ce:cross-ref> assumes a lower prevalence of 20% (although even this would be an unusually high prevalence for most diseases). Both the sensitivity and the specificity remain at 50%. Now only 200 of the 1,000 people have the disease, and the vertical line separating diseased from nondiseased persons is shifted to the left. The predictive value is now calculated as 100/500, or 20%.</ce:para><ce:para id="p0355">Given that we are screening a population with the lower prevalence rate, can we improve the predictive value? What would be the effect on predictive value if we increased the sensitivity of the test? <ce:cross-ref id="crf0285" refid="f0070">Fig. 5.13C</ce:cross-ref> shows the results when we leave the prevalence at 20% and the specificity at 50%, but increase the sensitivity to 90%. The predictive value is now 180/580, or 31%—a modest increase.</ce:para><ce:para id="p0360">What if, instead of increasing the sensitivity of the test, we increase its specificity? <ce:cross-ref id="crf0290" refid="f0070">Fig. 5.13D</ce:cross-ref> shows the results when prevalence remains 20% and sensitivity remains 50%, but specificity is increased to 90%. The predictive value is now 100/180, or 56%. Thus an increase in specificity resulted in a much greater increase in predictive value than the same increase in sensitivity.</ce:para><ce:para id="p0365">Why does specificity have a greater effect than sensitivity on predictive value? The answer becomes clear by examining these figures. Because we are dealing with infrequent diseases, most of the population falls to the right of the vertical line. Consequently, any change to the right of the vertical line affects a greater number of people than would a comparable change to the left of the line. Thus a change in specificity has a greater effect on predictive value than a comparable change in sensitivity. If we were dealing with a high-prevalence disease, the situation would be different.</ce:para><ce:para id="p0370">The effect of changes in specificity on predictive value is also seen in <ce:cross-ref id="crf0295" refid="t0055">Table 5.9</ce:cross-ref><ce:float-anchor refid="t0055"/> in a form similar to that used in <ce:cross-ref id="crf0300" refid="t0050">Table 5.8</ce:cross-ref>. As seen in this example, even with 100% sensitivity, a change in specificity from 70% to 95% has a dramatic effect on the PPV.</ce:para></ce:section></ce:section><ce:section id="s0075"><ce:section-title id="st0080">Reliability (Repeatability) of Tests</ce:section-title><ce:para id="p0375">Let's consider another aspect of assessing diagnostic and screening tests—the question of whether a test is reliable or repeatable. Can the results obtained be replicated (getting the same result) if the test is repeated? Clearly, regardless of the sensitivity and specificity of a test, if the test results cannot be reproduced, the value and usefulness of the test are minimal. The rest of this chapter focuses on the reliability or repeatability of diagnostic and screening tests. The factors that contribute to the variation between test results are discussed first: intrasubject variation (variation within individual subjects), intraobserver variation (variation in the reading of test results by the same reader), and interobserver variation (variation between those reading the test results).</ce:para><ce:section id="s0080"><ce:section-title id="st0085">Intrasubject Variation</ce:section-title><ce:para id="p0380">The values obtained in measuring many human characteristics often vary over time, even during a short period of 24 hours, or a longer period, such as seasonal variation. <ce:cross-ref id="crf0305" refid="f0075">Fig. 5.14</ce:cross-ref><ce:float-anchor refid="f0075"/> shows changes in blood pressure readings over a 24-hour period in 28 normotensive individuals. Variability over time is considerable. This, as well as the conditions under which certain tests are conducted (e.g., shortly after eating or post-exercise, at home or in a physician's office), clearly can lead to different results in the same individual. Therefore in evaluating any test result, it is important to consider the conditions under which the test was performed, including the time of day.</ce:para></ce:section><ce:section id="s0085"><ce:section-title id="st0090">Intraobserver Variation</ce:section-title><ce:para id="p0385">Sometimes variation occurs between two or more readings of the same test results made by the same observer. For example, a radiologist who reads the same group of x-rays at two different times may read one or more of the x-rays differently the second time. Tests and examinations differ in the degree to which subjective factors enter into the observer's conclusions, and the greater the subjective element in the reading, the greater the intraobserver variation in readings is likely to be (<ce:cross-ref id="crf0310" refid="f0080">Fig. 5.15</ce:cross-ref><ce:float-anchor refid="f0080"/>).</ce:para></ce:section><ce:section id="s0090"><ce:section-title id="st0095">Interobserver Variation</ce:section-title><ce:para id="p0390">Another important consideration is variation between observers. Two examiners often do not give the same result. The extent to which observers agree or disagree is an important issue, whether we are considering physical examinations, laboratory tests, or other means of assessing human characteristics. We therefore need to be able to express the extent of agreement in quantitative terms.</ce:para><ce:section id="s0095"><ce:section-title id="st0100">Percent Agreement</ce:section-title><ce:para id="p0395"><ce:cross-ref id="crf0315" refid="t0060">Table 5.10</ce:cross-ref><ce:float-anchor refid="t0060"/> shows a schema for examining variation between observers. Two observers were instructed to categorize each test result into one of the following four categories: abnormal, suspect, doubtful, and normal. This diagram might refer, for example, to readings performed by two radiologists. In this diagram, the readings of observer 1 are cross-tabulated against those of observer 2. The number of readings in each cell is denoted by a letter of the alphabet. Thus A x-rays were read as abnormal by both radiologists. C x-rays were read as abnormal by radiologist 2 and as doubtful by radiologist 1. M x-rays were read as abnormal by radiologist 1 and as normal by radiologist 2.</ce:para><ce:para id="p0400">As seen in <ce:cross-ref id="crf0320" refid="t0060">Table 5.10</ce:cross-ref>, to calculate the overall percent agreement, we add the numbers in all of the cells in which readings by both radiologists agreed (A + F + K + P), divide that sum by the total number of x-rays read, and multiply the result by 100 to yield a percentage. <ce:cross-ref id="crf0325" refid="f0085">Fig. 5.16A</ce:cross-ref><ce:float-anchor refid="f0085"/> shows the use of this approach for a test with possible readings of either “positive” or “negative.”</ce:para><ce:para id="p0405">In general, most persons who are tested have negative results. This is shown in <ce:cross-ref id="crf0330" refid="f0085">Fig. 5.16B</ce:cross-ref>, in which the size of each cell is drawn in proportion to the number of people in that cell. There is likely to be considerable agreement between the two observers about these negative, or normal, subjects (cell d). Therefore when percent agreement is calculated for all study subjects, its value may be high only because of the large number of clearly negative findings (cell d) on which the observers agree. Thus the high value may conceal significant disagreement between the observers in identifying subjects who are considered positive by at least one observer.</ce:para><ce:para id="p0410">One approach to this problem, seen in <ce:cross-ref id="crf0335" refid="f0085">Fig. 5.16C</ce:cross-ref>, is to disregard the subjects who were labeled negative by both observers (cell d) and to calculate percent agreement using as a denominator only the subjects who were labeled abnormal by at least one observer (cells a, b, and c; <ce:cross-ref id="crf0340" refid="f0085">Fig. 5.16D</ce:cross-ref>).</ce:para><ce:para id="p0415">Thus in the paired observations in which at least one of the findings in each pair was positive, the following equation is applicable:<ce:display><ce:formula id="e0020"><mml:math altimg="si3.gif" display="block" overflow="scroll"><mml:mrow><mml:mtext>Percent agreement</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mi mathvariant="normal">a</mml:mi><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:section><ce:section id="s0100"><ce:section-title id="st0105">Kappa Statistic</ce:section-title><ce:para id="p0420">Percent agreement between two observers is often of value in assessing the quality of their observations. The extent to which two observers, such as two physicians or two nurses, for example, agree with one another is often an important index of the quality of the health care being provided. However, the percent agreement between two observers does not entirely depend on the quality of their training and practice. The extent of their agreement is also significantly influenced by the fact that even if two observers use completely different criteria to identify subjects as positive or negative, we would expect the observers to agree about the observations made, at least in some of the participants, solely as a function of chance. What we really want to know is how much better their level of agreement is than that which results just from chance. The answer to this question will presumably tell us, for example, to what extent the education and training that the observers received improved the quality of their readings so that the percent agreement between them was increased beyond what we would expect from chance alone.</ce:para><ce:para id="p0425">This can be shown intuitively in the following example: you are the director of a radiology department that is understaffed 1 day, and a large number of chest x-rays remain to be read. To solve your problem, you go out to the street and ask a few neighborhood residents, who have no background in biology or medicine, to read the unread x-rays and assess them as either positive or negative. The first person goes through the pile of x-rays, reading them haphazardly as positive, negative, negative, positive, and so on. The second person does the same, in the same way, but completely independent of the first reader. Given that both readers have no knowledge, criteria, or standards for reading x-rays, would any of their readings on a specific x-ray agree? The answer is clearly yes; they would agree in some cases, purely by chance alone.</ce:para><ce:para id="p0430">However, if we want to know how well two observers read x-rays, we might ask, “To what extent do their readings agree <ce:italic>beyond what we would expect by chance alone</ce:italic>?” In other words, to what extent does the agreement between the two observers exceed the level of agreement that would result just from chance? One approach to answering this question is to calculate the kappa statistic, proposed by Cohen in 1960.<ce:cross-ref id="crf0345" refid="bib2"><ce:sup loc="post">2</ce:sup></ce:cross-ref> In this section, we will first discuss the rationale of the kappa statistic and the questions that the kappa statistic is designed to answer. This will be followed by a detailed calculation of the kappa statistic to serve as an example for intrepid readers. Even if you do not follow through the detailed calculation presented here, it is important to be sure that you understand the rationale of the kappa statistic because it is frequently applied both in clinical medicine and in public health.</ce:para><ce:section id="s0105"><ce:section-title id="st0110">Rationale of the Kappa Statistic.</ce:section-title><ce:para id="p0435">In order to understand kappa, we ask two questions. First, how much better is the agreement between the observers’ readings than would be expected by chance alone? This can be calculated as the percent agreement observed minus the percent agreement we would expect by chance alone. This is the numerator of kappa:<ce:display><ce:formula id="e0025"><mml:math altimg="si4.gif" display="block" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mo>(</mml:mo><mml:mtext>Percent agreement observed</mml:mtext><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:mtext>Percent agreement expected by chance alone</mml:mtext><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0440">Our second question is, “What is the most that the two observers could have improved their agreement over the agreement that would be expected by chance alone?” Clearly the maximum that they could agree would be 100% (full agreement, where the two observers agree completely). Therefore the most that we could expect them to be able to improve (the denominator of kappa) would be:<ce:display><ce:formula id="e0030"><mml:math altimg="si5.gif" display="block" overflow="scroll"><mml:mrow><mml:mn>100</mml:mn><mml:mi>%</mml:mi><mml:mo>−</mml:mo><mml:mo>(</mml:mo><mml:mtext>Percent agreement expected by chance alone</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0445">Kappa expresses the extent to which the observed agreement exceeds that which would be expected by chance alone (i.e., percent agreement observed − percent agreement expected by chance alone [numerator]) relative to the maximum that the observers could hope to improve their agreement (i.e., 100% − percent agreement expected by chance alone [denominator]).</ce:para><ce:para id="p0450">Thus kappa quantifies the extent to which the observed agreement that the observers achieved exceeds that which would be expected by chance alone, and expresses it as the proportion of the maximum improvement that could occur beyond the agreement expected by chance alone. The kappa statistic can be defined by the equation:<ce:display><ce:formula id="e0035"><mml:math altimg="si6.gif" display="block" overflow="scroll"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>Kappa</mml:mtext><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>observed</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>expected by chance alone</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>100</mml:mn><mml:mi>%</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>expected by chance alone</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para></ce:section><ce:section id="s0110"><ce:section-title id="st0115">Calculation of the Kappa Statistic: An Example.</ce:section-title><ce:para id="p0455">To calculate the numerator for kappa, we must first calculate the amount of agreement that might be expected on the basis of chance alone. As an example, let's consider data on breast density reported on the radiologic classification of breast density on synthetic 2D images as compared with digital 2D mammograms.<ce:cross-ref id="crf0350" refid="bib3"><ce:sup loc="post">3</ce:sup></ce:cross-ref> <ce:cross-ref id="crf0355" refid="f0090">Fig. 5.17A</ce:cross-ref><ce:float-anchor refid="f0090"/> shows data comparing the findings of the two methods in classifying 309 such cases.</ce:para><ce:para id="p0460">The first question is, “What is the observed agreement between the two types of mammograms?” <ce:cross-ref id="crf0360" refid="f0090">Fig. 5.17B</ce:cross-ref> shows the classifications using the synthetic 2D mammography along the bottom of the table and those of digital 2D mammography along the right margin. Thus synthetic 2D mammography identified 179 (or 58%) of all of the 309 breast images as nondense and 130 (or 42%) of the images as dense. Digital 2D mammography identified 182 (or 59%) of all of the images as nondense and 127 (or 41%) of the images as dense. As discussed earlier, the percent agreement is calculated by the following equation:<ce:display><ce:formula id="e0040"><mml:math altimg="si7.gif" display="block" overflow="scroll"><mml:mrow><mml:mtext>Percent agreement observed</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>168</mml:mn><mml:mo>+</mml:mo><mml:mn>116</mml:mn></mml:mrow><mml:mrow><mml:mn>309</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>91</mml:mn><mml:mo>.</mml:mo><mml:mtext>9%</mml:mtext></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0465">That is, the two mammography devices had the same breast image classification on 91.9% of the readings.</ce:para><ce:para id="p0470">The next question is, “If the two types of mammography had used entirely different sets of criteria for classifying a breast image as dense versus nondense, how much agreement would have been expected <ce:italic>solely on the basis of chance</ce:italic>?” Synthetic 2D mammography read 58% of all 309 images (179 images) as being nondense and 42% (130 images) as dense. If these readings had used criteria independent of those used by digital 2D mammography, we would expect that synthetic 2D mammography would read as nondense both 58% of the images that the digital had identified as dense and 58% of the images that digital 2D mammography had identified as dense. Therefore we would expect that 58% (73.44) of the 182 images identified as nondense by digital 2D mammography would be identified as nondense by synthetic 2D mammography, and that 58% (73.44) of the 127 images identified as dense by digital 2D mammography would also be identified as nondense by synthetic 2D mammography (see <ce:cross-ref id="crf0365" refid="f0085">Fig. 5.16C</ce:cross-ref>). Of the 127 images called dense by digital 2D mammography, 42% (53.34) would also be classified as dense by synthetic 2D mammography.</ce:para><ce:para id="p0475">Thus the agreement expected by chance alone would be<ce:display><ce:formula id="e0045"><mml:math altimg="si8.gif" display="block" overflow="scroll"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>105</mml:mn><mml:mo>.</mml:mo><mml:mn>56</mml:mn></mml:mrow><mml:mrow><mml:mn>309</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>53</mml:mn><mml:mo>.</mml:mo><mml:mn>34</mml:mn></mml:mrow><mml:mrow><mml:mn>309</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>158</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn></mml:mrow><mml:mrow><mml:mn>309</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>51</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0480">of all images read.</ce:para><ce:para id="p0485">Having calculated the figures needed for the numerator and denominator, kappa can now be calculated as follows:<ce:display><ce:formula id="e0050"><mml:math altimg="si9.gif" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:maligngroup/><mml:mtext>Kappa</mml:mtext><mml:mo>=</mml:mo><mml:malignmark/><mml:mfrac><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>observed</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>expected by</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>chance alone</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>100</mml:mn><mml:mi>%</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mtext>Percent agreement</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>expected by</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>chance alone</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:maligngroup/><mml:mo>=</mml:mo><mml:malignmark/><mml:mfrac><mml:mrow><mml:mn>91</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn><mml:mo>−</mml:mo><mml:mn>51</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn><mml:mo>−</mml:mo><mml:mn>51</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>40</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mrow><mml:mn>48</mml:mn><mml:mo>.</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>83</mml:mn><mml:mo>.</mml:mo><mml:mtext>3%</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para><ce:para id="p0490">Landis and Koch<ce:cross-ref id="crf0370" refid="bib4"><ce:sup loc="post">4</ce:sup></ce:cross-ref> suggested that a kappa greater than 0.75 represents excellent agreement beyond chance, a kappa below 0.40 represents poor agreement, and a kappa of 0.40 to 0.75 represents intermediate to good agreement. Testing for the statistical significance of kappa is described by Fleiss.<ce:cross-ref id="crf0375" refid="bib5"><ce:sup loc="post">5</ce:sup></ce:cross-ref> Considerable discussion has arisen about the appropriate use of kappa, a subject addressed by MacLure and Willett.<ce:cross-ref id="crf0380" refid="bib6"><ce:sup loc="post">6</ce:sup></ce:cross-ref></ce:para></ce:section><ce:section id="s0115"><ce:section-title id="st0120">Validity of Tests With Multicategorical Results.</ce:section-title><ce:para id="p0495">Validity, as a concept, can be applied to any test against a gold standard. As we explained earlier, we use sensitivity/specificity to validate the results of tests with dichotomous results against a gold standard. What about tests with multicategorical results? In this case, we can calculate kappa statistic, which we demonstrated earlier as a tool to assess reliability.</ce:para></ce:section><ce:section id="s0120"><ce:section-title id="st0125">Validity of Self-Reports.</ce:section-title><ce:para id="p0500">Often we obtain information on health and disease status by directly asking patients or study participants about their medical history, their habits, and other factors of interest. Most people today know their date of birth, so the assessment of age is usually without significant error. However, many people underreport their weight, their drinking and smoking practices, and other types of risks. Self-reports of sexual behaviors are considered to be subject to considerable error. To overcome these reporting biases, biomarkers have become commonly used in field studies. For example, Zenilman et al.<ce:cross-ref id="crf0385" refid="bib7"><ce:sup loc="post">7</ce:sup></ce:cross-ref> used a polymerase chain reaction (PCR) assay to detect Y chromosome fragments in self-collected vaginal swabs. This biomarker can detect coitus in women for a 2-week period, and can validate self-reports of condom use.<ce:cross-ref id="crf0390" refid="bib8"><ce:sup loc="post">8</ce:sup></ce:cross-ref></ce:para></ce:section></ce:section></ce:section></ce:section><ce:section id="s0125"><ce:section-title id="st0130">Relationship Between Validity and Reliability</ce:section-title><ce:para id="p0505">To conclude this chapter, let's compare validity and reliability using a graphical presentation.</ce:para><ce:para id="p0510">The horizontal line in <ce:cross-ref id="crf0395" refid="f0095">Fig. 5.18</ce:cross-ref><ce:float-anchor refid="f0095"/> is a scale of values for a given variable, such as blood glucose level, with the true value indicated. The test results obtained are shown by the curve. The curve is narrow, indicating that the results are quite reliable (repeatable); unfortunately, however, they cluster far from the true value, so they are not valid. <ce:cross-ref id="crf0400" refid="f0100">Fig. 5.19</ce:cross-ref><ce:float-anchor refid="f0100"/> shows a curve that is broad and therefore has low reliability. However, the values obtained cluster around the true value and thus are valid. Clearly, what we would like to achieve are results that are both valid and reliable (<ce:cross-ref id="crf0405" refid="f0105">Fig. 5.20</ce:cross-ref><ce:float-anchor refid="f0105"/>).</ce:para><ce:para id="p0515">It is important to point out that in <ce:cross-ref id="crf0410" refid="f0105">Fig. 5.20</ce:cross-ref>, in which the distribution of the test results is a broad curve centered on the true value, we describe the results as valid. However, the results are valid only for a group (i.e., they tend to cluster around the true value). It is important to remember that what may be valid for a group or a population may not be so for an individual in a clinical setting. When the reliability or repeatability of a test is poor, the validity of the test for a given individual also may be poor. The distinction between group validity and individual validity is therefore important to keep in mind when assessing the quality of diagnostic and screening tests.</ce:para></ce:section><ce:section id="s0130" role="conclusion"><ce:section-title id="st0135">Conclusion</ce:section-title><ce:para id="p0520">This chapter has discussed the validity of diagnostic and screening tests as measured by their sensitivity and specificity, their predictive value, and the reliability or repeatability of these tests. Clearly, regardless of how sensitive and specific a test may be, if its results cannot be replicated, the test is of little use. All these characteristics must therefore be borne in mind when evaluating such tests, together with the purpose for which the test will be used.</ce:para></ce:section></ce:sections><ce:bibliography id="bb0010"><ce:section-title id="st0140">References</ce:section-title><ce:bibliography-sec id="bs0010"><ce:bib-reference id="bib1"><ce:label>1</ce:label><sb:reference id="sr0010"><sb:contribution langtype="en"><sb:title><sb:maintitle>Prenatal diagnosis</sb:maintitle></sb:title></sb:contribution><sb:host><sb:edited-book><sb:editors><sb:editor><ce:given-name>F</ce:given-name><ce:surname>Cunningham</ce:surname></sb:editor><sb:editor><ce:given-name>KJ</ce:given-name><ce:surname>Leveno</ce:surname></sb:editor><sb:editor><ce:given-name>SL</ce:given-name><ce:surname>Bloom</ce:surname></sb:editor><sb:et-al/></sb:editors><sb:title><sb:maintitle>Williams Obstetrics. <ce:italic>24th ed</ce:italic></sb:maintitle></sb:title><sb:date>2013</sb:date><sb:publisher><sb:name>McGraw-Hill</sb:name><sb:location>New York</sb:location></sb:publisher></sb:edited-book></sb:host><sb:host><sb:e-host><ce:inter-ref id="iw0015" xlink:href="http://accessmedicine.mhmedical.com.ezp.welch.jhmi.edu/content.aspx?bookid=1057&amp;sectionid=59789152">http://accessmedicine.mhmedical.com.ezp.welch.jhmi.edu/content.aspx?bookid=1057&amp;sectionid=59789152</ce:inter-ref><sb:date-accessed day="19" month="6" year="2017"/></sb:e-host></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib2"><ce:label>2</ce:label><sb:reference id="sr0015"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>J</ce:given-name><ce:surname>Cohen</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>A coefficient of agreement for nominal scales</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Educ Psychol Meas</sb:maintitle></sb:title><sb:volume-nr>20</sb:volume-nr></sb:series><sb:date>1960</sb:date></sb:issue><sb:pages><sb:first-page>37</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib3"><ce:label>3</ce:label><sb:reference id="sr0020"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>TI</ce:given-name><ce:surname>Alshafeiy</ce:surname></sb:author><sb:author><ce:given-name>A</ce:given-name><ce:surname>Wadih</ce:surname></sb:author><sb:author><ce:given-name>BT</ce:given-name><ce:surname>Nicholson</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Comparison between digital and synthetic 2D mammograms in breast density interpretation</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>AJR Am J Roentgenol</sb:maintitle></sb:title><sb:volume-nr>209</sb:volume-nr></sb:series><sb:date>2017</sb:date></sb:issue><sb:pages><sb:first-page>W36</sb:first-page><sb:last-page>W41</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib4"><ce:label>4</ce:label><sb:reference id="sr0025"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>JR</ce:given-name><ce:surname>Landis</ce:surname></sb:author><sb:author><ce:given-name>GG</ce:given-name><ce:surname>Koch</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>The measurement of observer agreement for categorical data</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Biometrics</sb:maintitle></sb:title><sb:volume-nr>33</sb:volume-nr></sb:series><sb:date>1977</sb:date></sb:issue><sb:pages><sb:first-page>159</sb:first-page><sb:last-page>174</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib5"><ce:label>5</ce:label><sb:reference id="sr0030"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>JL</ce:given-name><ce:surname>Fleiss</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Statistical Methods for Rates and Proportions</sb:maintitle></sb:title></sb:contribution><sb:host><sb:book><sb:edition>2nd ed</sb:edition><sb:date>1981</sb:date><sb:publisher><sb:name>John Wiley &amp; Sons</sb:name><sb:location>New York</sb:location></sb:publisher></sb:book></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib6"><ce:label>6</ce:label><sb:reference id="sr0035"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>M</ce:given-name><ce:surname>MacLure</ce:surname></sb:author><sb:author><ce:given-name>WC</ce:given-name><ce:surname>Willett</ce:surname></sb:author></sb:authors><sb:title><sb:maintitle>Misinterpretation and misuse of the kappa statistic</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Am J Epidemiol</sb:maintitle></sb:title><sb:volume-nr>126</sb:volume-nr></sb:series><sb:date>1987</sb:date></sb:issue><sb:pages><sb:first-page>161</sb:first-page><sb:last-page>169</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib7"><ce:label>7</ce:label><sb:reference id="sr0040"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>JM</ce:given-name><ce:surname>Zenilman</ce:surname></sb:author><sb:author><ce:given-name>J</ce:given-name><ce:surname>Yeunger</ce:surname></sb:author><sb:author><ce:given-name>N</ce:given-name><ce:surname>Galai</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Polymerase chain reaction detection of Y chromosome sequences in vaginal fluid: preliminary studies of a potential biomarker</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Sex Transm Dis</sb:maintitle></sb:title><sb:volume-nr>32</sb:volume-nr></sb:series><sb:date>2005</sb:date></sb:issue><sb:pages><sb:first-page>90</sb:first-page><sb:last-page>94</sb:last-page></sb:pages></sb:host></sb:reference></ce:bib-reference><ce:bib-reference id="bib8"><ce:label>8</ce:label><sb:reference id="sr0045"><sb:contribution langtype="en"><sb:authors><sb:author><ce:given-name>KG</ce:given-name><ce:surname>Ghanem</ce:surname></sb:author><sb:author><ce:given-name>JH</ce:given-name><ce:surname>Melendez</ce:surname></sb:author><sb:author><ce:given-name>C</ce:given-name><ce:surname>McNeil-Solis</ce:surname></sb:author><sb:et-al/></sb:authors><sb:title><sb:maintitle>Condom use and vaginal Y-chromosome detection: the specificity of a potential biomarker</sb:maintitle></sb:title></sb:contribution><sb:host><sb:issue><sb:series><sb:title><sb:maintitle>Sex Transm Dis</sb:maintitle></sb:title><sb:volume-nr>34</sb:volume-nr></sb:series><sb:date>2007</sb:date></sb:issue><sb:pages><sb:first-page>620</sb:first-page></sb:pages></sb:host></sb:reference></ce:bib-reference></ce:bibliography-sec></ce:bibliography><ce:section id="s0135"><ce:section-title id="st0145">Appendices to Chapter 5</ce:section-title><ce:para id="p0525">The text of Chapter 5 focuses on the logic behind the calculation of sensitivity, specificity, and predictive value. Appendix 1 summarizes measures of validity for screening tests to detect the absence or presence of a given disease, the pages in the text where the measures are first introduced, and the interpretation of each measure. For those who prefer to see the formulae for each measure, they are provided in the right-hand column of this table; however, they are not essential for understanding the logic behind the calculation of each measure.<ce:display><ce:table frame="topbot" id="t0065"><ce:caption id="ca0160"><ce:simple-para id="sp0175" role="title">Appendix 1 to Chapter 5: Measures of Test Validity and Their Interpretation</ce:simple-para></ce:caption><ce:alt-text id="atte0185" role="short">Unlabelled table</ce:alt-text><tgroup cols="5"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><colspec colname="col3" colnum="3"/><colspec colname="col4" colnum="4"/><colspec colname="col5" colnum="5"/><thead><row rowsep="1"><entry align="left"/><entry align="left">Measure of Test Validity</entry><entry align="left">Page Numbers</entry><entry align="left">Interpretation</entry><entry align="center">Formula</entry></row></thead><tbody><row rowsep="0"><entry morerows="3" align="center">INDIVIDUAL screening tests</entry><entry align="left">Sensitivity</entry><entry align="left"><ce:cross-ref id="crf9025" refid="s0015">95</ce:cross-ref></entry><entry align="left">The proportion of those <ce:italic>with</ce:italic> the disease who test <ce:italic>positive</ce:italic></entry><entry align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0225" locator="if005-001-9780323552295" xlink:href="pii:B978032355229500005X/if005-001-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0190" role="short">Image 5</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">Specificity</entry><entry align="left"><ce:cross-ref id="crf9030" refid="s0015">95</ce:cross-ref></entry><entry align="left">The proportion of those <ce:italic>without</ce:italic> the disease who test <ce:italic>negative</ce:italic></entry><entry align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0230" locator="if005-002-9780323552295" xlink:href="pii:B978032355229500005X/if005-002-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0195" role="short">Image 6</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">Positive predictive value</entry><entry align="left"><ce:cross-ref id="crf9035" refid="s0060">106–107</ce:cross-ref></entry><entry align="left">The proportion of those who test <ce:italic>positive</ce:italic> who do have the disease</entry><entry align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0235" locator="if005-003-9780323552295" xlink:href="pii:B978032355229500005X/if005-003-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0200" role="short">Image 7</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">Negative predictive value</entry><entry align="left"><ce:cross-ref id="crf9040" refid="p0260">107</ce:cross-ref></entry><entry align="left">The proportion of those who test <ce:italic>negative</ce:italic> who do NOT have the disease</entry><entry align="center"><ce:inline-figure baseline="0.0"><ce:link id="ln0240" locator="if005-004-9780323552295" xlink:href="pii:B978032355229500005X/if005-004-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0205" role="short">Image 8</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry morerows="1" align="center">SEQUENTIAL screening tests</entry><entry align="left">Net sensitivity</entry><entry align="left"><ce:cross-ref id="crf9045" refid="p0115">99–101</ce:cross-ref></entry><entry align="left">The proportion of those <ce:italic>with</ce:italic> the disease who test <ce:italic>positive</ce:italic> on BOTH Test 1 and Test 2</entry><entry align="left"><ce:inline-figure baseline="0.0"><ce:link id="ln0245" locator="if005-005-9780323552295" xlink:href="pii:B978032355229500005X/if005-005-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0210" role="short">Image 9</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">Net specificity</entry><entry align="left"><ce:cross-ref id="crf9050" refid="p0115">99–101</ce:cross-ref></entry><entry align="left">The proportion of those <ce:italic>without</ce:italic> the disease who test <ce:italic>negative</ce:italic> on EITHER Test 1 or Test 2</entry><entry align="left"><ce:inline-figure baseline="0.0"><ce:link id="ln0250" locator="if005-006-9780323552295" xlink:href="pii:B978032355229500005X/if005-006-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0215" role="short">Image 10</ce:alt-text></ce:inline-figure></entry></row><row><entry morerows="1" align="center">SIMULTANEOUS screening tests</entry><entry rowsep="0" align="left">Net sensitivity</entry><entry rowsep="0" align="left"><ce:cross-ref id="crf9055" refid="p0170">101–104</ce:cross-ref></entry><entry rowsep="0" align="left">The proportion of those <ce:italic>with</ce:italic> the disease who test <ce:italic>positive</ce:italic> on EITHER Test 1 or Test 2</entry><entry rowsep="0" align="left"><ce:inline-figure baseline="0.0"><ce:link id="ln0255" locator="if005-007-9780323552295" xlink:href="pii:B978032355229500005X/if005-007-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0220" role="short">Image 11</ce:alt-text></ce:inline-figure></entry></row><row><entry align="left">Net specificity</entry><entry align="left"><ce:cross-ref id="crf9060" refid="s0055">105–106</ce:cross-ref></entry><entry align="left">The proportion of those <ce:italic>without</ce:italic> the disease who test <ce:italic>negative</ce:italic> on BOTH Test 1 and Test 2</entry><entry align="left"><ce:inline-figure baseline="0.0"><ce:link id="ln0260" locator="if005-008-9780323552295" xlink:href="pii:B978032355229500005X/if005-008-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0225" role="short">Image 12</ce:alt-text></ce:inline-figure></entry></row></tbody></tgroup><ce:legend><ce:simple-para id="sp0180"><ce:italic>FN</ce:italic>, False negatives; <ce:italic>FP</ce:italic>, false positives; <ce:italic>TN</ce:italic>, true negatives; <ce:italic>TP</ce:italic>, true positives.</ce:simple-para></ce:legend></ce:table></ce:display></ce:para><ce:para id="p0530">Appendix 2 summarizes the three steps required to calculate kappa statistic.<ce:display><ce:table frame="topbot" id="t0070"><ce:caption id="ca0165"><ce:simple-para id="sp0185" role="title">Appendix 2 to Chapter 5: The Three Steps Required for Calculating Kappa Statistic (κ)</ce:simple-para></ce:caption><ce:alt-text id="atte0230" role="short">Unlabelled table</ce:alt-text><tgroup cols="2"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><thead><row rowsep="1"><entry align="left">Components</entry><entry align="center">Steps</entry></row></thead><tbody><row rowsep="0"><entry align="left">NUMERATOR</entry><entry morerows="1" align="center">STEP 1:<ce:br/><ce:inline-figure baseline="0.0"><ce:link id="ln0265" locator="if005-009-9780323552295" xlink:href="pii:B978032355229500005X/if005-009-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0235" role="short">Image 13</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">How much better is the observed agreement than the agreement expected by chance alone?</entry></row><row rowsep="0"><entry align="left">DENOMINATOR</entry><entry morerows="1" align="center">STEP 2:<ce:br/><ce:inline-figure baseline="0.0"><ce:link id="ln0270" locator="if005-010-9780323552295" xlink:href="pii:B978032355229500005X/if005-010-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0240" role="short">Image 14</ce:alt-text></ce:inline-figure></entry></row><row rowsep="0"><entry align="left">What is the maximum the observers could have improved upon the agreement expected by chance alone?</entry></row><row><entry rowsep="0" align="left"><ce:inline-figure baseline="0.0"><ce:link id="ln0275" locator="if005-011-9780323552295" xlink:href="pii:B978032355229500005X/if005-011-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0245" role="short">Image 15</ce:alt-text></ce:inline-figure></entry><entry morerows="1" align="center">STEP 3:<ce:br/><ce:inline-figure baseline="0.0"><ce:link id="ln0280" locator="if005-012-9780323552295" xlink:href="pii:B978032355229500005X/if005-012-9780323552295" xlink:role="http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4" xlink:type="simple"/><ce:alt-text id="atte0250" role="short">Image 16</ce:alt-text></ce:inline-figure></entry></row><row><entry align="left">Of the maximum improvement in agreement expected beyond chance alone that could have occurred, what proportion has in fact occurred?</entry></row></tbody></tgroup><ce:legend><ce:simple-para id="sp0190">A full discussion of kappa and a sample calculation starts on <ce:cross-ref id="crf9065" refid="s0100">page 113</ce:cross-ref>.</ce:simple-para></ce:legend></ce:table></ce:display></ce:para></ce:section><exam id="em0010"><ce:exam-questions id="xq0010"><ce:section-title id="st0150">Review Questions for Chapter 5</ce:section-title><ce:para id="p0535"><ce:bold>Questions 1, 2, and 3 are based on the information given below:</ce:bold></ce:para><ce:para id="p0540">A physical examination was used to screen for breast cancer in 2,500 women with biopsy-proven adenocarcinoma of the breast and in 5,000 age- and race-matched control women. The results of the physical examination were positive (i.e., a mass was palpated) in 1,800 cases and in 800 control women, all of whom showed no evidence of cancer at biopsy.<ce:list id="olist0015"><ce:list-item id="o0035"><ce:label>1</ce:label><ce:para id="p0545"><ce:italic>The sensitivity of the physical examination was: ______</ce:italic></ce:para></ce:list-item><ce:list-item id="o0040"><ce:label>2</ce:label><ce:para id="p0550"><ce:italic>The specificity of the physical examination was: ______</ce:italic></ce:para></ce:list-item><ce:list-item id="o0045"><ce:label>3</ce:label><ce:para id="p0555"><ce:italic>The positive predictive value of the physical examination was: ______</ce:italic></ce:para><ce:para id="p0560"><ce:bold>Question 4 is based on the following information:</ce:bold></ce:para><ce:para id="p0565">A screening test is used in the same way in two similar populations, but the proportion of false-positive results among those who test positive in population A is lower than that among those who test positive in population B.</ce:para></ce:list-item><ce:list-item id="o0050"><ce:label>4</ce:label><ce:para id="p0570"><ce:italic>What is the likely explanation for this finding?</ce:italic><ce:list id="olist0020"><ce:list-item id="o0055"><ce:label>a.</ce:label><ce:para id="p0575">It is impossible to determine what caused the difference</ce:para></ce:list-item><ce:list-item id="o0060"><ce:label>b.</ce:label><ce:para id="p0580">The specificity of the test is lower in population A</ce:para></ce:list-item><ce:list-item id="o0065"><ce:label>c.</ce:label><ce:para id="p0585">The prevalence of disease is lower in population A</ce:para></ce:list-item><ce:list-item id="o0070"><ce:label>d.</ce:label><ce:para id="p0590">The prevalence of disease is higher in population A</ce:para></ce:list-item><ce:list-item id="o0075"><ce:label>e.</ce:label><ce:para id="p0595">The specificity of the test is higher in population A</ce:para></ce:list-item></ce:list></ce:para><ce:para id="p0600"><ce:bold>Question 5 is based on the following information:</ce:bold></ce:para><ce:para id="p0605">A physical examination and an audiometric test were given to 500 persons with suspected hearing problems, of whom 300 were actually found to have them. The results of the examinations were as follows:<ce:display><ce:table frame="topbot" id="t0075"><ce:alt-text id="atte0255" role="short">Unlabelled table</ce:alt-text><tgroup cols="3"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><colspec colname="col3" colnum="3"/><thead><row rowsep="1"><entry morerows="1" align="left">Result</entry><entry namest="col2" nameend="col3" align="center"><ce:small-caps>hearing problems</ce:small-caps></entry></row><row role="tcolhead1" rowsep="1"><entry align="left">Present</entry><entry align="left">Absent</entry></row></thead><tbody><row role="thead1" rowsep="1"><entry namest="col1" nameend="col3" align="left"><ce:bold>Physical Examination</ce:bold></entry></row><row rowsep="0"><entry align="left">Positive</entry><entry align="left">240</entry><entry align="left">40</entry></row><row rowsep="1"><entry align="left">Negative</entry><entry align="left">60</entry><entry align="left">160</entry></row><row role="thead1" rowsep="1"><entry namest="col1" nameend="col3" align="left"><ce:bold>Audiometric Test</ce:bold></entry></row><row rowsep="0"><entry align="left">Positive</entry><entry align="left">270</entry><entry align="left">60</entry></row><row><entry align="left">Negative</entry><entry align="left">30</entry><entry align="left">140</entry></row></tbody></tgroup></ce:table></ce:display></ce:para></ce:list-item><ce:list-item id="o0080"><ce:label>5</ce:label><ce:para id="p0610"><ce:italic>Compared with the physical examination, the audiometric test is:</ce:italic><ce:list id="olist0025"><ce:list-item id="o0085"><ce:label>a.</ce:label><ce:para id="p0615">Equally sensitive and specific</ce:para></ce:list-item><ce:list-item id="o0090"><ce:label>b.</ce:label><ce:para id="p0620">Less sensitive and less specific</ce:para></ce:list-item><ce:list-item id="o0095"><ce:label>c.</ce:label><ce:para id="p0625">Less sensitive and more specific</ce:para></ce:list-item><ce:list-item id="o0100"><ce:label>d.</ce:label><ce:para id="p0630">More sensitive and less specific</ce:para></ce:list-item><ce:list-item id="o0105"><ce:label>e.</ce:label><ce:para id="p0635">More sensitive and more specific</ce:para></ce:list-item></ce:list></ce:para><ce:para id="p0640"><ce:bold>Question 6 is based on the following information:</ce:bold></ce:para><ce:para id="p0645">Two pediatricians want to investigate a new laboratory test that identifies streptococcal infections. Dr. Kidd uses the standard culture test, which has a sensitivity of 90% and a specificity of 96%. Dr. Childs uses the new test, which is 96% sensitive and 96% specific.</ce:para></ce:list-item><ce:list-item id="o0110"><ce:label>6</ce:label><ce:para id="p0650"><ce:italic>If 200 patients undergo culture with both tests, which of the following is correct?</ce:italic><ce:list id="olist0030"><ce:list-item id="o0115"><ce:label>a.</ce:label><ce:para id="p0655">Dr. Kidd will correctly identify more people with streptococcal infection than Dr. Childs</ce:para></ce:list-item><ce:list-item id="o0120"><ce:label>b.</ce:label><ce:para id="p0660">Dr. Kidd will correctly identify fewer people with streptococcal infection than Dr. Childs</ce:para></ce:list-item><ce:list-item id="o0125"><ce:label>c.</ce:label><ce:para id="p0665">Dr. Kidd will correctly identify more people without streptococcal infection than Dr. Childs</ce:para></ce:list-item><ce:list-item id="o0130"><ce:label>d.</ce:label><ce:para id="p0670">The prevalence of streptococcal infection is needed to determine which pediatrician will correctly identify the larger number of people with the disease</ce:para></ce:list-item></ce:list></ce:para><ce:para id="p0675"><ce:bold>Questions 7 and 8 are based on the following information:</ce:bold></ce:para><ce:para id="p0680">A colon cancer screening study is being conducted in Nottingham, England. Individuals 50 to 75 years old will be screened with the Hemoccult test. In this test, a stool sample is tested for the presence of blood.</ce:para></ce:list-item><ce:list-item id="o0135"><ce:label>7</ce:label><ce:para id="p0685"><ce:italic>The Hemoccult test has a sensitivity of 70% and a specificity of 75%. If Nottingham has a prevalence of 12/1,000 for colon cancer, what is the positive predictive value of the test? _____</ce:italic></ce:para></ce:list-item><ce:list-item id="o0140"><ce:label>8</ce:label><ce:para id="p0690"><ce:italic>If the Hemoccult test result is negative, no further testing is done. If the Hemoccult test result is positive, the individual will have a second stool sample tested with the Hemoccult II test. If this second sample also tests positive for blood, the individual will be referred for more extensive evaluation. What is the effect on net sensitivity and net specificity of this method of screening?</ce:italic><ce:list id="olist0035"><ce:list-item id="o0145"><ce:label>a.</ce:label><ce:para id="p0695">Net sensitivity and net specificity are both increased</ce:para></ce:list-item><ce:list-item id="o0150"><ce:label>b.</ce:label><ce:para id="p0700">Net sensitivity is decreased and net specificity is increased</ce:para></ce:list-item><ce:list-item id="o0155"><ce:label>c.</ce:label><ce:para id="p0705">Net sensitivity remains the same and net specificity is increased</ce:para></ce:list-item><ce:list-item id="o0160"><ce:label>d.</ce:label><ce:para id="p0710">Net sensitivity is increased and net specificity is decreased</ce:para></ce:list-item><ce:list-item id="o0165"><ce:label>e.</ce:label><ce:para id="p0715">The effect on net sensitivity and net specificity cannot be determined from the data</ce:para></ce:list-item></ce:list></ce:para><ce:para id="p0720"><ce:bold>Questions 9 through 12 are based on the information given below:</ce:bold></ce:para><ce:para id="p0725">Two physicians were asked to classify 100 chest x-rays as abnormal or normal independently. The comparison of their classification is shown in the following table:<ce:display><ce:table frame="topbot" id="t0080"><ce:caption id="ca0170"><ce:simple-para id="sp0195" role="title">Classification of Chest X-Rays by Physician 1 Compared With Physician 2</ce:simple-para></ce:caption><ce:alt-text id="atte0260" role="short">Unlabelled table</ce:alt-text><tgroup cols="4"><colspec colname="col1" colnum="1"/><colspec colname="col2" colnum="2"/><colspec colname="col3" colnum="3"/><colspec colname="col4" colnum="4"/><thead><row rowsep="1"><entry morerows="1" align="left">Physician 1</entry><entry namest="col2" nameend="col4" align="center">Physician 2</entry></row><row role="tcolhead1" rowsep="1"><entry align="left">Abnormal</entry><entry align="left">Normal</entry><entry align="left">Total</entry></row></thead><tbody><row rowsep="0"><entry align="left">Abnormal</entry><entry align="center">40</entry><entry align="center">20</entry><entry align="left">60</entry></row><row rowsep="0"><entry align="left">Normal</entry><entry align="center">10</entry><entry align="center">30</entry><entry align="left">40</entry></row><row><entry align="left">Total</entry><entry align="center">50</entry><entry align="center">50</entry><entry align="left">100</entry></row></tbody></tgroup></ce:table></ce:display></ce:para></ce:list-item><ce:list-item id="o0170"><ce:label>9</ce:label><ce:para id="p0730"><ce:italic>The simple percent agreement between the two physicians out of the total is: ______</ce:italic></ce:para></ce:list-item><ce:list-item id="o0175"><ce:label>10</ce:label><ce:para id="p0735"><ce:italic>The percent agreement between the two physicians, excluding the x-rays that both physicians classified as normal, is: ______</ce:italic></ce:para></ce:list-item><ce:list-item id="o0180"><ce:label>11</ce:label><ce:para id="p0740"><ce:italic>The value of kappa is: ______</ce:italic></ce:para></ce:list-item><ce:list-item id="o0185"><ce:label>12</ce:label><ce:para id="p0745"><ce:italic>This value of kappa represents what level of agreement?</ce:italic><ce:list id="olist0040"><ce:list-item id="o0190"><ce:label>a.</ce:label><ce:para id="p0750">Excellent</ce:para></ce:list-item><ce:list-item id="o0195"><ce:label>b.</ce:label><ce:para id="p0755">Intermediate to good</ce:para></ce:list-item><ce:list-item id="o0200"><ce:label>c.</ce:label><ce:para id="p0760">Poor</ce:para></ce:list-item></ce:list></ce:para></ce:list-item></ce:list></ce:para></ce:exam-questions></exam></chapter>